{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import DictReader, DictWriter\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from functools import reduce\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26061997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
       "1  1917                     [213]           1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "2  1918        [1263, 1969, 1188]           0  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]   \n",
       "4  1920                     [424]           0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [1.0, 0.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [1.0, 0.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_testing_file_path = \"data/testing/markables.csv\"\n",
    "\n",
    "data = get_markable_dataframe(data_testing_file_path, word_vector, idx_by_word)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "label = np.vstack(data.is_singleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model = load_model('models/singleton_classifiers/words.model')\n",
    "context_model = load_model('models/singleton_classifiers/context.model')\n",
    "syntactic_model = load_model('models/singleton_classifiers/syntactic.model')\n",
    "words_context_model = load_model('models/singleton_classifiers/words_context.model')\n",
    "words_syntactic_model = load_model('models/singleton_classifiers/words_syntactic.model')\n",
    "context_syntactic_model = load_model('models/singleton_classifiers/context_syntactic.model')\n",
    "words_context_syntactic_model = load_model('models/singleton_classifiers/words_context_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(output, threshold=0.5):\n",
    "    return list(map(lambda x: 1 if x[1] > threshold else 0, output))\n",
    "\n",
    "def evaluate(label, pred, threshold=0.5):\n",
    "    label = get_classes(label)\n",
    "    pred = get_classes(pred, threshold)\n",
    "    \n",
    "    print('threshold %f:' % threshold)\n",
    "    print(classification_report(label, pred))\n",
    "    print('accuracy: %f' % accuracy_score(label, pred))\n",
    "\n",
    "def evaluate_all(label, pred):\n",
    "    for i in range(1, 10):\n",
    "        evaluate(label, pred, i*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pred = words_model.predict([data_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.45      0.59       105\n",
      "           1       0.92      0.99      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.89      0.72      0.77       798\n",
      "weighted avg       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.917293\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.45      0.58       105\n",
      "           1       0.92      0.99      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.87      0.72      0.77       798\n",
      "weighted avg       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.45      0.57       105\n",
      "           1       0.92      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.86      0.72      0.76       798\n",
      "weighted avg       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.48      0.59       105\n",
      "           1       0.92      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.85      0.73      0.77       798\n",
      "weighted avg       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.75      0.68       105\n",
      "           1       0.96      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.84      0.81       798\n",
      "weighted avg       0.92      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.904762\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.84      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.77      0.84      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.66       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.77      0.84      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.895990\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.80      0.67       105\n",
      "           1       0.97      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.86      0.81       798\n",
      "weighted avg       0.92      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_pred = context_model.predict([data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.36      0.47       105\n",
      "           1       0.91      0.97      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.78      0.67      0.70       798\n",
      "weighted avg       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.890977\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.38      0.48       105\n",
      "           1       0.91      0.97      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.67      0.71       798\n",
      "weighted avg       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.889724\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48       105\n",
      "           1       0.91      0.97      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.68      0.71       798\n",
      "weighted avg       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.889724\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.49       105\n",
      "           1       0.91      0.96      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.69      0.72       798\n",
      "weighted avg       0.88      0.89      0.88       798\n",
      "\n",
      "accuracy: 0.889724\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.41      0.48       105\n",
      "           1       0.91      0.96      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.75      0.68      0.71       798\n",
      "weighted avg       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.883459\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.43      0.48       105\n",
      "           1       0.92      0.95      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.74      0.69      0.71       798\n",
      "weighted avg       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.879699\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.43      0.48       105\n",
      "           1       0.92      0.95      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.73      0.69      0.71       798\n",
      "weighted avg       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.878446\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.43      0.48       105\n",
      "           1       0.92      0.95      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.73      0.69      0.71       798\n",
      "weighted avg       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.878446\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.46      0.49       105\n",
      "           1       0.92      0.94      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.73      0.70      0.71       798\n",
      "weighted avg       0.87      0.88      0.87       798\n",
      "\n",
      "accuracy: 0.877193\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_pred = syntactic_model.predict([data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.10      0.18       105\n",
      "           1       0.88      0.99      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.76      0.55      0.56       798\n",
      "weighted avg       0.85      0.87      0.83       798\n",
      "\n",
      "accuracy: 0.874687\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.69       105\n",
      "           1       0.97      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.87      0.82       798\n",
      "weighted avg       0.92      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.69       105\n",
      "           1       0.97      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.87      0.82       798\n",
      "weighted avg       0.92      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.86      0.67       105\n",
      "           1       0.98      0.89      0.93       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.88      0.80       798\n",
      "weighted avg       0.92      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.888471\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.94      0.62       105\n",
      "           1       0.99      0.83      0.91       693\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       798\n",
      "   macro avg       0.73      0.89      0.76       798\n",
      "weighted avg       0.92      0.85      0.87       798\n",
      "\n",
      "accuracy: 0.848371\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.96      0.61       105\n",
      "           1       0.99      0.82      0.90       693\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       798\n",
      "   macro avg       0.72      0.89      0.75       798\n",
      "weighted avg       0.92      0.84      0.86       798\n",
      "\n",
      "accuracy: 0.835840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/turfa/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_pred = words_context_model.predict([data_text, data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65       105\n",
      "           1       0.94      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.85      0.77      0.80       798\n",
      "weighted avg       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65       105\n",
      "           1       0.94      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.84      0.77      0.80       798\n",
      "weighted avg       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.918546\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       105\n",
      "           1       0.94      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.78      0.80       798\n",
      "weighted avg       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.916040\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.78      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.913534\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.78      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.913534\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.78      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.913534\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.79      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.914787\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.82      0.80      0.81       798\n",
      "weighted avg       0.91      0.92      0.91       798\n",
      "\n",
      "accuracy: 0.916040\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67       105\n",
      "           1       0.95      0.95      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.81      0.81      0.81       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.914787\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_pred = words_syntactic_model.predict([data_text, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.39      0.53       105\n",
      "           1       0.91      0.99      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.86      0.69      0.74       798\n",
      "weighted avg       0.90      0.91      0.89       798\n",
      "\n",
      "accuracy: 0.907268\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.41      0.54       105\n",
      "           1       0.92      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.85      0.70      0.74       798\n",
      "weighted avg       0.90      0.91      0.89       798\n",
      "\n",
      "accuracy: 0.907268\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.47      0.57       105\n",
      "           1       0.92      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.83      0.72      0.76       798\n",
      "weighted avg       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.48      0.58       105\n",
      "           1       0.92      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.83      0.73      0.76       798\n",
      "weighted avg       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       105\n",
      "           1       0.96      0.93      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.79      0.85      0.81       798\n",
      "weighted avg       0.92      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.907268\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68       105\n",
      "           1       0.96      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.79      0.84      0.81       798\n",
      "weighted avg       0.92      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.906015\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.84      0.81       798\n",
      "weighted avg       0.92      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67       105\n",
      "           1       0.96      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.77      0.85      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.79      0.66       105\n",
      "           1       0.97      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.85      0.80       798\n",
      "weighted avg       0.91      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.894737\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_pred = context_syntactic_model.predict([data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68       105\n",
      "           1       0.94      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.85      0.80      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.924812\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       798\n",
      "   macro avg       0.86      0.81      0.83       798\n",
      "weighted avg       0.92      0.93      0.92       798\n",
      "\n",
      "accuracy: 0.927318\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.85      0.81      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.924812\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       105\n",
      "           1       0.95      0.96      0.96       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.84      0.81      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.922306\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.81      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.921053\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.81      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.81      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.82      0.82       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.921053\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       105\n",
      "           1       0.95      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.82      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.921053\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_pred = words_context_syntactic_model.predict([\n",
    "    data_text, data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       798\n",
      "   macro avg       0.87      0.81      0.83       798\n",
      "weighted avg       0.93      0.93      0.93       798\n",
      "\n",
      "accuracy: 0.929825\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.85      0.81      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.924812\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       798\n",
      "   macro avg       0.85      0.82      0.83       798\n",
      "weighted avg       0.92      0.93      0.93       798\n",
      "\n",
      "accuracy: 0.927318\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       105\n",
      "           1       0.95      0.97      0.96       693\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       798\n",
      "   macro avg       0.85      0.82      0.83       798\n",
      "weighted avg       0.92      0.93      0.93       798\n",
      "\n",
      "accuracy: 0.927318\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       105\n",
      "           1       0.95      0.96      0.96       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.83      0.83      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.923559\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       105\n",
      "           1       0.96      0.95      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.82      0.83      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.919799\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70       105\n",
      "           1       0.96      0.94      0.95       693\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       798\n",
      "   macro avg       0.81      0.84      0.83       798\n",
      "weighted avg       0.92      0.92      0.92       798\n",
      "\n",
      "accuracy: 0.917293\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       105\n",
      "           1       0.97      0.93      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.80      0.86      0.83       798\n",
      "weighted avg       0.92      0.91      0.92       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       105\n",
      "           1       0.97      0.90      0.93       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.85      0.79       798\n",
      "weighted avg       0.91      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.888471\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richer Markable Data with Predicted Singleton (for coreference resolution testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data_testing_file_path = \"data/testing/markables_with_predicted_singleton.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_testing_file_path, \"r\") as orifile:\n",
    "    oricsv = DictReader(orifile)\n",
    "    \n",
    "    with open(rich_data_testing_file_path, \"w\") as newfile:\n",
    "        newcsv = DictWriter(newfile, fieldnames=oricsv.fieldnames)\n",
    "        \n",
    "        newcsv.writeheader()\n",
    "        \n",
    "        for row, is_singleton in zip(oricsv, get_classes(words_context_syntactic_pred, 0.4)):\n",
    "            newcsv.writerow({**row, 'is_singleton': is_singleton})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TA",
   "language": "python",
   "name": "ta-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
