{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import DictReader, DictWriter\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from functools import reduce\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26061997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>num_words</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1258, 1259, 1955, 1389]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[996, 377, 1156, 212, 26, 1258, 1956, 1183, 14...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[212]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1258, 1259, 1955, 1389, 996, 377, 1156]</td>\n",
       "      <td>[26, 1258, 1956, 1183, 1464, 24, 1156, 62, 422...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1258, 1956, 1183]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1258, 1259, 1955, 1389, 996, 377, 1156, 212, 26]</td>\n",
       "      <td>[1464, 24, 1156, 62, 422, 1218, 24, 1409, 1156...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1464, 24, 1156]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1955, 1389, 996, 377, 1156, 212, 26, 1258, 19...</td>\n",
       "      <td>[62, 422, 1218, 24, 1409, 1156, 874, 342, 212,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[422]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1156, 212, 26, 1258, 1956, 1183, 1464, 24, 11...</td>\n",
       "      <td>[1218, 24, 1409, 1156, 874, 342, 212, 404, 121...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1258, 1259, 1955, 1389]           0  [0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
       "1  1917                     [212]           1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "2  1918        [1258, 1956, 1183]           0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 1]   \n",
       "3  1919          [1464, 24, 1156]           0  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0]   \n",
       "4  1920                     [422]           0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  num_words  \\\n",
       "0               1                0          4   \n",
       "1               0                0          1   \n",
       "2               1                0          3   \n",
       "3               0                0          3   \n",
       "4               0                0          1   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1258, 1259, 1955, 1389, 996, 377, 1156]   \n",
       "2  [1258, 1259, 1955, 1389, 996, 377, 1156, 212, 26]   \n",
       "3  [1955, 1389, 996, 377, 1156, 212, 26, 1258, 19...   \n",
       "4  [1156, 212, 26, 1258, 1956, 1183, 1464, 24, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [996, 377, 1156, 212, 26, 1258, 1956, 1183, 14...   [1.0, 0.0]  \n",
       "1  [26, 1258, 1956, 1183, 1464, 24, 1156, 62, 422...   [1.0, 0.0]  \n",
       "2  [1464, 24, 1156, 62, 422, 1218, 24, 1409, 1156...   [1.0, 0.0]  \n",
       "3  [62, 422, 1218, 24, 1409, 1156, 874, 342, 212,...   [0.0, 1.0]  \n",
       "4  [1218, 24, 1409, 1156, 874, 342, 212, 404, 121...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_testing_file_path = \"data/testing/markables.csv\"\n",
    "\n",
    "data = get_markable_dataframe(data_testing_file_path, word_vector, idx_by_word)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person', 'num_words']]\n",
    "\n",
    "data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "label = np.vstack(data.is_singleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model = load_model('models/singleton_classifiers/words.model')\n",
    "context_model = load_model('models/singleton_classifiers/context.model')\n",
    "syntactic_model = load_model('models/singleton_classifiers/syntactic.model')\n",
    "words_context_model = load_model('models/singleton_classifiers/words_context.model')\n",
    "words_syntactic_model = load_model('models/singleton_classifiers/words_syntactic.model')\n",
    "context_syntactic_model = load_model('models/singleton_classifiers/context_syntactic.model')\n",
    "words_context_syntactic_model = load_model('models/singleton_classifiers/words_context_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(output, threshold=0.5):\n",
    "    return list(map(lambda x: 1 if x[1] > threshold else 0, output))\n",
    "\n",
    "def evaluate(label, pred, threshold=0.5):\n",
    "    label = get_classes(label)\n",
    "    pred = get_classes(pred, threshold)\n",
    "    \n",
    "    print('threshold %f:' % threshold)\n",
    "    print(classification_report(label, pred))\n",
    "    print('accuracy: %f' % accuracy_score(label, pred))\n",
    "\n",
    "def evaluate_all(label, pred):\n",
    "    for i in range(1, 10):\n",
    "        evaluate(label, pred, i*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_pred = words_model.predict([data_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29       105\n",
      "           1       0.89      1.00      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.94      0.59      0.62       798\n",
      "weighted avg       0.90      0.89      0.86       798\n",
      "\n",
      "accuracy: 0.890977\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.26      0.40       105\n",
      "           1       0.90      0.99      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.88      0.63      0.67       798\n",
      "weighted avg       0.89      0.90      0.87       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.31      0.45       105\n",
      "           1       0.90      0.99      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.85      0.65      0.70       798\n",
      "weighted avg       0.89      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.37      0.49       105\n",
      "           1       0.91      0.98      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.81      0.67      0.72       798\n",
      "weighted avg       0.88      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       105\n",
      "           1       0.94      0.94      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.79      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.62       105\n",
      "           1       0.95      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.80      0.78       798\n",
      "weighted avg       0.90      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.894737\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.62       105\n",
      "           1       0.95      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.80      0.78       798\n",
      "weighted avg       0.90      0.89      0.89       798\n",
      "\n",
      "accuracy: 0.889724\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.72      0.63       105\n",
      "           1       0.96      0.91      0.93       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.82      0.78       798\n",
      "weighted avg       0.90      0.89      0.89       798\n",
      "\n",
      "accuracy: 0.887218\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.63       105\n",
      "           1       0.97      0.89      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.75      0.85      0.78       798\n",
      "weighted avg       0.91      0.88      0.89       798\n",
      "\n",
      "accuracy: 0.878446\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_pred = context_model.predict([data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.17      0.27       105\n",
      "           1       0.89      0.98      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.75      0.58      0.60       798\n",
      "weighted avg       0.85      0.88      0.85       798\n",
      "\n",
      "accuracy: 0.877193\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.21      0.30       105\n",
      "           1       0.89      0.97      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.72      0.59      0.62       798\n",
      "weighted avg       0.85      0.87      0.85       798\n",
      "\n",
      "accuracy: 0.873434\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.28      0.36       105\n",
      "           1       0.90      0.96      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.70      0.62      0.64       798\n",
      "weighted avg       0.85      0.87      0.85       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.31      0.39       105\n",
      "           1       0.90      0.95      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.70      0.63      0.66       798\n",
      "weighted avg       0.85      0.87      0.86       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.42       105\n",
      "           1       0.91      0.94      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.70      0.65      0.67       798\n",
      "weighted avg       0.85      0.87      0.86       798\n",
      "\n",
      "accuracy: 0.867168\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47       105\n",
      "           1       0.92      0.94      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.71      0.69      0.70       798\n",
      "weighted avg       0.86      0.87      0.87       798\n",
      "\n",
      "accuracy: 0.869674\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49       105\n",
      "           1       0.92      0.92      0.92       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.71      0.70      0.71       798\n",
      "weighted avg       0.87      0.87      0.87       798\n",
      "\n",
      "accuracy: 0.865915\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.52      0.48       105\n",
      "           1       0.93      0.90      0.91       693\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       798\n",
      "   macro avg       0.68      0.71      0.70       798\n",
      "weighted avg       0.86      0.85      0.86       798\n",
      "\n",
      "accuracy: 0.850877\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.61      0.46       105\n",
      "           1       0.93      0.84      0.89       693\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       798\n",
      "   macro avg       0.65      0.73      0.67       798\n",
      "weighted avg       0.86      0.81      0.83       798\n",
      "\n",
      "accuracy: 0.810777\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_pred = syntactic_model.predict([data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       0.87      1.00      0.93       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.43      0.50      0.46       798\n",
      "weighted avg       0.75      0.87      0.81       798\n",
      "\n",
      "accuracy: 0.868421\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57       105\n",
      "           1       0.94      0.94      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.75      0.75       798\n",
      "weighted avg       0.89      0.89      0.89       798\n",
      "\n",
      "accuracy: 0.888471\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.59       105\n",
      "           1       0.95      0.91      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.74      0.79      0.76       798\n",
      "weighted avg       0.89      0.88      0.88       798\n",
      "\n",
      "accuracy: 0.879699\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.72      0.62       105\n",
      "           1       0.96      0.91      0.93       693\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       798\n",
      "   macro avg       0.75      0.82      0.77       798\n",
      "weighted avg       0.90      0.88      0.89       798\n",
      "\n",
      "accuracy: 0.882206\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.86      0.58       105\n",
      "           1       0.97      0.84      0.90       693\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       798\n",
      "   macro avg       0.71      0.85      0.74       798\n",
      "weighted avg       0.90      0.84      0.86       798\n",
      "\n",
      "accuracy: 0.839599\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.86      0.57       105\n",
      "           1       0.97      0.83      0.89       693\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       798\n",
      "   macro avg       0.70      0.84      0.73       798\n",
      "weighted avg       0.90      0.83      0.85       798\n",
      "\n",
      "accuracy: 0.830827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/turfa/.pyenv/versions/miniconda3-latest/envs/ta-v2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_pred = words_context_model.predict([data_text, data_previous_words, data_next_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.47      0.59       105\n",
      "           1       0.92      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.86      0.72      0.77       798\n",
      "weighted avg       0.91      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.913534\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60       105\n",
      "           1       0.93      0.98      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.84      0.74      0.77       798\n",
      "weighted avg       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.61       105\n",
      "           1       0.93      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.75      0.78       798\n",
      "weighted avg       0.90      0.91      0.90       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.76      0.79       798\n",
      "weighted avg       0.90      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.911028\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61       105\n",
      "           1       0.94      0.95      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.76      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       105\n",
      "           1       0.94      0.95      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.77      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62       105\n",
      "           1       0.94      0.95      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.77      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.902256\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62       105\n",
      "           1       0.94      0.94      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.79      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62       105\n",
      "           1       0.95      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.76      0.80      0.78       798\n",
      "weighted avg       0.90      0.89      0.89       798\n",
      "\n",
      "accuracy: 0.890977\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_pred = words_syntactic_model.predict([data_text, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.29      0.44       105\n",
      "           1       0.90      1.00      0.95       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.93      0.64      0.69       798\n",
      "weighted avg       0.91      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.904762\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.31      0.47       105\n",
      "           1       0.91      1.00      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.91      0.65      0.71       798\n",
      "weighted avg       0.91      0.91      0.89       798\n",
      "\n",
      "accuracy: 0.906015\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.34      0.47       105\n",
      "           1       0.91      0.98      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.83      0.66      0.71       798\n",
      "weighted avg       0.89      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.45      0.55       105\n",
      "           1       0.92      0.97      0.95       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.82      0.71      0.75       798\n",
      "weighted avg       0.89      0.90      0.89       798\n",
      "\n",
      "accuracy: 0.904762\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.67       105\n",
      "           1       0.95      0.94      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.79      0.82      0.81       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.907268\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.68       105\n",
      "           1       0.96      0.94      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.80      0.83      0.81       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.68       105\n",
      "           1       0.96      0.94      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.80      0.83      0.81       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.74      0.68       105\n",
      "           1       0.96      0.93      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.79      0.84      0.81       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.906015\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.77      0.83      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.895990\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_pred = context_syntactic_model.predict([data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.36      0.48       105\n",
      "           1       0.91      0.98      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.82      0.67      0.71       798\n",
      "weighted avg       0.89      0.90      0.88       798\n",
      "\n",
      "accuracy: 0.898496\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.46      0.55       105\n",
      "           1       0.92      0.97      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.80      0.71      0.75       798\n",
      "weighted avg       0.89      0.90      0.89       798\n",
      "\n",
      "accuracy: 0.901003\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.59       105\n",
      "           1       0.93      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.80      0.74      0.77       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.80      0.76      0.78       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.904762\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63       105\n",
      "           1       0.94      0.95      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.78      0.79       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.903509\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63       105\n",
      "           1       0.95      0.94      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.80      0.79       798\n",
      "weighted avg       0.90      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65       105\n",
      "           1       0.95      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.82      0.80       798\n",
      "weighted avg       0.91      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.902256\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.65       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.83      0.80       798\n",
      "weighted avg       0.91      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.894737\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.77      0.61       105\n",
      "           1       0.96      0.88      0.92       693\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       798\n",
      "   macro avg       0.73      0.83      0.77       798\n",
      "weighted avg       0.90      0.87      0.88       798\n",
      "\n",
      "accuracy: 0.869674\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context + Syntactic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_pred = words_context_syntactic_model.predict([\n",
    "    data_text, data_previous_words, data_next_words, data_syntactic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.100000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.77      0.79       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.200000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65       105\n",
      "           1       0.94      0.96      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.82      0.78      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.912281\n",
      "threshold 0.300000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64       105\n",
      "           1       0.94      0.95      0.95       693\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       798\n",
      "   macro avg       0.80      0.79      0.80       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "accuracy: 0.908521\n",
      "threshold 0.400000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       105\n",
      "           1       0.95      0.94      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.79      0.81      0.80       798\n",
      "weighted avg       0.91      0.90      0.91       798\n",
      "\n",
      "accuracy: 0.904762\n",
      "threshold 0.500000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.64       105\n",
      "           1       0.95      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.81      0.79       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.600000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65       105\n",
      "           1       0.95      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.81      0.79       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.899749\n",
      "threshold 0.700000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.66       105\n",
      "           1       0.96      0.93      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.78      0.82      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.901003\n",
      "threshold 0.800000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66       105\n",
      "           1       0.96      0.92      0.94       693\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       798\n",
      "   macro avg       0.77      0.83      0.80       798\n",
      "weighted avg       0.91      0.90      0.90       798\n",
      "\n",
      "accuracy: 0.897243\n",
      "threshold 0.900000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.76      0.66       105\n",
      "           1       0.96      0.91      0.94       693\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       798\n",
      "   macro avg       0.77      0.84      0.80       798\n",
      "weighted avg       0.91      0.89      0.90       798\n",
      "\n",
      "accuracy: 0.894737\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(label, words_context_syntactic_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richer Markable Data with Predicted Singleton (for coreference resolution testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data_testing_file_path = \"data/testing/markables_with_predicted_singleton.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_testing_file_path, \"r\") as orifile:\n",
    "    oricsv = DictReader(orifile)\n",
    "    \n",
    "    with open(rich_data_testing_file_path, \"w\") as newfile:\n",
    "        newcsv = DictWriter(newfile, fieldnames=oricsv.fieldnames)\n",
    "        \n",
    "        newcsv.writeheader()\n",
    "        \n",
    "        for row, is_singleton in zip(oricsv, get_classes(words_syntactic_pred, 0.6)):\n",
    "            newcsv.writerow({**row, 'is_singleton': is_singleton})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TA",
   "language": "python",
   "name": "ta-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
