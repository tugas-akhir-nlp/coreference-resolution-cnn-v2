{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.coreference_classifier import CoreferenceClassifierModelBuilder\n",
    "from functools import reduce\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.clusterers import BestFirstClusterer, get_anaphora_scores_by_antecedent, ClosestFirstClusterer\n",
    "from utils.scorers import MUCScorer, B3Scorer, AverageScorer\n",
    "from utils.data_structures import UFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1]   \n",
       "1  1917                     [213]           1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "2  1918        [1263, 1969, 1188]           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "4  1920                     [424]           0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [0.0, 1.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [0.0, 1.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markables = get_markable_dataframe(\"data/testing/markables_with_predicted_singleton.csv\", word_vector, idx_by_word)\n",
    "singletons = set(markables[markables['is_singleton'].map(lambda x: True if x[1] > 0 else False)]['id'])\n",
    "markables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1_id</th>\n",
       "      <th>m2_id</th>\n",
       "      <th>is_exact_match</th>\n",
       "      <th>is_words_match</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>is_abbreviation</th>\n",
       "      <th>is_appositive</th>\n",
       "      <th>is_nearest_candidate</th>\n",
       "      <th>sentence_distance</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>markable_distance</th>\n",
       "      <th>is_coreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1916</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m1_id  m2_id  is_exact_match  is_words_match  is_substring  \\\n",
       "0   1916   1917               0               0             0   \n",
       "1   1916   1918               0               0             0   \n",
       "2   1916   1919               0               0             0   \n",
       "3   1916   1920               0               0             0   \n",
       "4   1916   1921               0               0             0   \n",
       "\n",
       "   is_abbreviation  is_appositive  is_nearest_candidate  sentence_distance  \\\n",
       "0                0              0                     1                  0   \n",
       "1                0              0                     0                  0   \n",
       "2                0              0                     0                  0   \n",
       "3                0              0                     0                  0   \n",
       "4                0              0                     0                  0   \n",
       "\n",
       "   word_distance  markable_distance  is_coreference  \n",
       "0              3                  1               1  \n",
       "1              5                  2               0  \n",
       "2              8                  3               0  \n",
       "3             12                  4               0  \n",
       "4             13                  5               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.read_csv(\"data/testing/mention_pairs.csv\")\n",
    "\n",
    "label = np.vstack(to_categorical(pairs.is_coreference, num_classes=2))\n",
    "label_chains = ClosestFirstClusterer().get_chains(get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label))\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "def get_data(markable_ids):\n",
    "    indices = reduce(lambda a, b: a + [b], map(lambda a: markables.index[markables['id'] == a].tolist()[0], markable_ids), [])\n",
    "    data = markables.loc[indices]\n",
    "    \n",
    "    data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "    data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "    data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "    data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "    data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "    is_singleton = np.vstack(data.is_singleton)\n",
    "    \n",
    "    return data_text, data_previous_words, data_next_words, data_syntactic, is_singleton\n",
    "\n",
    "def get_pair_data(markable_ids_1, markable_ids_2):\n",
    "    text_1, prev_1, next_1, syntactic_1, is_singleton_1 = get_data(markable_ids_1)\n",
    "    text_2, prev_2, next_2, syntactic_2, is_singleton_2 = get_data(markable_ids_2)\n",
    "    \n",
    "    return text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2\n",
    "\n",
    "def get_relation_data(mention_pairs):\n",
    "    return mention_pairs[['is_exact_match', 'is_words_match', 'is_substring', 'is_abbreviation', 'is_appositive', 'is_nearest_candidate', 'sentence_distance', 'word_distance', 'markable_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUC:  (0.5544554455445545, 0.7272727272727273, 0.6292134831460674)\n",
      "B3:  (0.3124361294443262, 0.6732829670329671, 0.4268110965737344)\n",
      "Average:  (0.5280122898599009, 0.5280122898599009, 0.5280122898599009)\n"
     ]
    }
   ],
   "source": [
    "baseline_result_file_path = 'baseline/test_result.txt'\n",
    "\n",
    "baseline_ufds = UFDS()\n",
    "\n",
    "for m1, m2 in zip(pairs.m1_id, pairs.m2_id):\n",
    "    baseline_ufds.init_id(m1, m2)\n",
    "    \n",
    "for line in open(baseline_result_file_path, 'r').readlines():\n",
    "    line = line.split(', ')\n",
    "    baseline_ufds.join(int(line[0]), int(line[1]))\n",
    "\n",
    "baseline_chains = baseline_ufds.get_chain_list()\n",
    "\n",
    "print('MUC: ', MUCScorer().get_scores(baseline_chains, label_chains))\n",
    "print('B3: ', B3Scorer().get_scores(baseline_chains, label_chains))\n",
    "print('Average: ', AverageScorer([MUCScorer(), B3Scorer()]).get_scores(baseline_chains, label_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2 = get_pair_data(pairs.m1_id, pairs.m2_id)\n",
    "relation = get_relation_data(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "def get_model(features, data_generation, epoch):\n",
    "    name = '_'.join([*features, data_generation, str(epoch)])\n",
    "    \n",
    "    if name not in models:\n",
    "        models[name] = load_model(f'models/coreference_classifiers/{name}.model')\n",
    "    \n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_thresholds = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "thresholds = [0] + [base * multiplier for base in base_thresholds for multiplier in range(1, 10)]\n",
    "\n",
    "muc_scorer = MUCScorer()\n",
    "b3_scorer = B3Scorer()\n",
    "average_scorer = AverageScorer([muc_scorer, b3_scorer])\n",
    "\n",
    "def get_sorted_scores(clusterer, pred):\n",
    "    scores = [] # will be a tuple (average_f1, (prec_muc, rec_muc, f1_muc), (prec_b3, rec_b3, f1_b3), threshold)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predicted_chains = clusterer.get_chains(pred, threshold)\n",
    "        \n",
    "#         avg_f1 = average_scorer.get_scores(predicted_chains, label_chains)[2]\n",
    "        muc = muc_scorer.get_scores(predicted_chains, label_chains)\n",
    "        b3 = b3_scorer.get_scores(predicted_chains, label_chains)\n",
    "        avg_f1 = (muc[2] + b3[2]) / 2\n",
    "        \n",
    "        scores.append((avg_f1, muc, b3, threshold))\n",
    "    \n",
    "    return sorted(scores, reverse=True)\n",
    "\n",
    "def evaluate(features, data_generation, epoch):\n",
    "    model = get_model(features, data_generation, epoch)\n",
    "    \n",
    "    test_features = []\n",
    "    if 'words' in features:\n",
    "        test_features.extend([text_1, text_2])\n",
    "    if 'context' in features:\n",
    "        test_features.extend([prev_1, prev_2, next_1, next_2])\n",
    "    if 'syntactic' in features:\n",
    "        test_features.extend([syntactic_1, syntactic_2, relation])\n",
    "    \n",
    "    print('getting anaphora scores by antecedent dict')\n",
    "    raw_pred = model.predict(test_features, verbose=1)\n",
    "    pred_without_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred)\n",
    "    pred_with_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred, singletons)\n",
    "    \n",
    "    print('get sorted_scores_without_sc_closest')\n",
    "    sorted_scores_without_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, closest-first:', sorted_scores_without_sc_closest[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_closest')\n",
    "    sorted_scores_with_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, closest-first:', sorted_scores_with_sc_closest[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_without_sc_best')\n",
    "    sorted_scores_without_sc_best = get_sorted_scores(BestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, best-first:', sorted_scores_without_sc_best[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_best')\n",
    "    sorted_scores_with_sc_best = get_sorted_scores(BestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, best-first:', sorted_scores_with_sc_best[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0401 05:45:48.619380 139999969802048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0401 05:45:48.623163 139999969802048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0401 05:45:48.624130 139999969802048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0401 05:45:48.641584 139999969802048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0401 05:45:48.642737 139999969802048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 4s 168us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.40268219804618965, (0.4111111111111111, 0.4805194805194805, 0.4431137724550898), (0.3176070428171268, 0.4214972527472528, 0.36225062363728955), 0.07)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5561313845271152, (0.5894736842105263, 0.7272727272727273, 0.6511627906976745), (0.3505823974005792, 0.6733745421245423, 0.46109997835655586), 0.002)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.43106769113480564, (0.4375, 0.5454545454545454, 0.48554913294797686), (0.31022056455940744, 0.47907509157509165, 0.3765862493216344), 0.06)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5561313845271152, (0.5894736842105263, 0.7272727272727273, 0.6511627906976745), (0.3505823974005792, 0.6733745421245423, 0.46109997835655586), 0.002)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 4s 159us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.47892857821862, (0.64, 0.4155844155844156, 0.5039370078740157), (0.6042617960426179, 0.3634844322344322, 0.4539201485632242), 0.07)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5456840460771337, (0.5591397849462365, 0.6753246753246753, 0.6117647058823529), (0.3860544217687075, 0.6329899267399269, 0.47960338627191446), 0.001)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.5009281618024803, (0.6538461538461539, 0.44155844155844154, 0.5271317829457364), (0.6009259259259259, 0.3923305860805861, 0.4747245406592243), 0.06)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5516078956345187, (0.5698924731182796, 0.6883116883116883, 0.623529411764706), (0.3835263835263835, 0.6402014652014654, 0.4796863795043314), 0.001)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 4s 169us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.4127603382276283, (0.8214285714285714, 0.2987012987012987, 0.4380952380952381), (0.8118518518518518, 0.2544184981684982, 0.3874254383600185), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5473389599833366, (0.5670103092783505, 0.7142857142857143, 0.6321839080459771), (0.3552794796157628, 0.6623855311355312, 0.4624940119206961), 1e-05)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.4259544779106286, (0.373134328358209, 0.6493506493506493, 0.4739336492890996), (0.2725667712194659, 0.6163232600732601, 0.37797530653215766), 0.0009000000000000001)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5462740753170315, (0.5670103092783505, 0.7142857142857143, 0.6321839080459771), (0.3527721049844943, 0.6623855311355312, 0.46036424258808595), 1e-05)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gilang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.scorers' from '/home/m13515133/ta/utils/scorers.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils.scorers\n",
    "importlib.reload(utils.scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 4s 166us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.4999867495480671, (0.5384615384615384, 0.5454545454545454, 0.5419354838709678), (0.4154696705667579, 0.5103250915750918, 0.4580380152251664), 0.4)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5326126495434207, (0.56, 0.7272727272727273, 0.632768361581921), (0.31850376634859395, 0.6733745421245423, 0.4324569375049205), 0.07)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.5255750302135886, (0.5333333333333333, 0.7272727272727273, 0.6153846153846153), (0.32275970695970707, 0.6705357142857145, 0.4357654450425619), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5630509018557133, (0.6144578313253012, 0.6623376623376623, 0.6375), (0.40797247307148304, 0.6089514652014653, 0.4886018037114265), 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 198us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.5647287334026654, (0.5714285714285714, 0.6753246753246753, 0.619047619047619), (0.43289034411915767, 0.6217490842490843, 0.5104098477577117), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5556106498269193, (0.5822784810126582, 0.5974025974025974, 0.5897435897435898), (0.49021035598705504, 0.5570054945054945, 0.5214777099102488), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.6036155932625624, (0.6043956043956044, 0.7142857142857143, 0.6547619047619048), (0.47355946522613196, 0.6629349816849819, 0.5524692817632202), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5875367585402943, (0.620253164556962, 0.6363636363636364, 0.6282051282051282), (0.5118932038834951, 0.5869734432234434, 0.5468683888754604), 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 214us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.5184275982323026, (0.5353535353535354, 0.6883116883116883, 0.6022727272727273), (0.3249547583563977, 0.6558379120879121, 0.4345824691918777), 0.5)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5216915111575184, (0.5377358490566038, 0.7402597402597403, 0.6229508196721312), (0.3027465021317481, 0.6877976190476193, 0.42043220264290565), 0.0004)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.5282585449030317, (0.5555555555555556, 0.7142857142857143, 0.6250000000000001), (0.3143578410385132, 0.6878891941391942, 0.43151708980606335), 0.5)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.541768714251329, (0.5670103092783505, 0.7142857142857143, 0.6321839080459771), (0.3419334288899506, 0.6637591575091577, 0.45135352045668087), 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 228us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.22233896688169175, (0.16981132075471697, 0.23376623376623376, 0.19672131147540983), (0.22547892720306514, 0.27541208791208793, 0.24795662228797363), 0.4)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5367740041321248, (0.5454545454545454, 0.7012987012987013, 0.6136363636363636), (0.35511666204943515, 0.6524496336996338, 0.459911644627886), 0.03)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.27800606260551897, (0.2222222222222222, 0.36363636363636365, 0.27586206896551724), (0.22254257605820107, 0.37799908424908424, 0.28015005624552075), 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5322101478719172, (0.5454545454545454, 0.7012987012987013, 0.6136363636363636), (0.3453133730676103, 0.6490155677655678, 0.4507839321074709), 0.03)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 6s 242us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.24958934372675887, (0.19327731092436976, 0.2987012987012987, 0.23469387755102045), (0.21631762652705064, 0.3402472527472528, 0.2644848099024973), 0.8)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5409834191712287, (0.5591397849462365, 0.6753246753246753, 0.6117647058823529), (0.37772476061949745, 0.6226419413919415, 0.47020213246010456), 0.2)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.2960392335260301, (0.25165562913907286, 0.4935064935064935, 0.33333333333333337), (0.17898462246288335, 0.466735347985348, 0.25874513371872687), 0.7000000000000001)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5523230038808579, (0.5806451612903226, 0.7012987012987013, 0.6352941176470589), (0.370000645000645, 0.641643772893773, 0.4693518901146568), 0.2)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 6s 259us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.27714422095212093, (0.22321428571428573, 0.3246753246753247, 0.2645502645502646), (0.25402621722846447, 0.33713369963369966, 0.2897381773539773), 0.9)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5358512357691024, (0.5632183908045977, 0.6363636363636364, 0.5975609756097561), (0.4033739960345465, 0.5750228937728938, 0.4741414959284488), 0.04)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.3845036743049909, (0.34710743801652894, 0.5454545454545454, 0.42424242424242425), (0.26655971479500895, 0.48791208791208796, 0.34476492436755746), 0.8)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5581816067269094, (0.5975609756097561, 0.6363636363636364, 0.6163522012578616), (0.4516874711049469, 0.5599130036630038, 0.5000110121959573), 0.1)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markable_text(idx):\n",
    "    return [word_by_idx[x] for x in markables[markables['id'] == idx].text.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23689/23689==============================] - 5s 223us/sample\n"
     ]
    }
   ],
   "source": [
    "best_model = models['words_context_syntactic_gilang_10']\n",
    "raw_pred_best = best_model.predict([text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, relation], verbose=1)\n",
    "pred_best = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred_best)\n",
    "pred_chains_best = BestFirstClusterer().get_chains(pred_best, 0.30000000000000004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['deputi', 'gubernur'],\n",
       "  ['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['ia']],\n",
       " [['bi'], ['bi']],\n",
       " [['nya'], ['nya'], ['nya']],\n",
       " [['ansari'], ['ansari']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['mulyani']],\n",
       " [['pt', 'astra', 'agro', 'lestari', 'tbk'],\n",
       "  ['aali'],\n",
       "  ['nya'],\n",
       "  ['direktur', 'aali'],\n",
       "  ['santosa'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['deputi', 'senior'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['miranda'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['nya']],\n",
       " [['bank', 'mandiri'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['ia'],\n",
       "  ['nya'],\n",
       "  ['bank', 'mandiri']],\n",
       " [['nya'], ['nya'], ['nya']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati'],\n",
       "  ['nya'],\n",
       "  ['menko', 'perekonomian', 'boediono'],\n",
       "  ['nya'],\n",
       "  ['boediono'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['pefindo'], ['dia']],\n",
       " [['trje'], ['pt', 'tri', 'usaha', 'bhakti'], ['trje'], ['trje']],\n",
       " [['nya'], ['nya'], ['nya']],\n",
       " [['adb'], ['adb'], ['adb']],\n",
       " [['nya'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['menhut'],\n",
       "  ['plta', 'genyem'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['dewo']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['ia']],\n",
       " [['fitri', 'barnas'], ['nya']],\n",
       " [['pt', 'perusahaan', 'gas', 'negara', 'persero', 'tbk'], ['pgas']],\n",
       " [['anwar'], ['nya'], ['nya'], ['nya'], ['nya'], ['ia']],\n",
       " [['dpr'], ['dpr'], ['dpr']],\n",
       " [['indonesia'], ['indonesia']],\n",
       " [['fitch'], ['nya'], ['nya'], ['nya'], ['fitch'], ['nya']],\n",
       " [['pt', 'astra', 'otoparts', 'tbk'],\n",
       "  ['nya'],\n",
       "  ['pt', 'exedy', 'indonesia'],\n",
       "  ['nya'],\n",
       "  ['exedy', 'corporation'],\n",
       "  ['pt', 'astra', 'otoparts'],\n",
       "  ['pt', 'exedy', 'indonesia'],\n",
       "  ['nya'],\n",
       "  ['nya']],\n",
       " [['sekretaris', 'perusahaan', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia']],\n",
       " [['menkeu', 'sri', 'mulyani', 'indrawati'], ['dia']]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in pred_chains_best if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['deputi', 'gubernur'], ['bank', 'indonesia']],\n",
       " [['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['jakarta'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['kami'],\n",
       "  ['sekretaris', 'perusahaan', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['menkeu', 'sri', 'mulyani', 'indrawati'],\n",
       "  ['dia']],\n",
       " [['ia'],\n",
       "  ['dirjend',\n",
       "   'industri',\n",
       "   'logam',\n",
       "   'mesin',\n",
       "   'tekstil',\n",
       "   'departemen',\n",
       "   'perindustrian',\n",
       "   'ansari',\n",
       "   'bukhari'],\n",
       "  ['ansari'],\n",
       "  ['ansari']],\n",
       " [['indonesia', 'investor', 'forum'], ['indonesia', 'investor', 'forum']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['nya']],\n",
       " [['direktur', 'aali'],\n",
       "  ['santosa'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['deputi', 'senior'],\n",
       "  ['bank', 'indonesia'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['miranda'],\n",
       "  ['kami'],\n",
       "  ['nya'],\n",
       "  ['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda']],\n",
       " [['pertumbuhan', 'ekonomi', 'indonesia'],\n",
       "  ['pertumbuhan', 'ekonomi', 'indonesia'],\n",
       "  ['pertumbuhan', 'ekonomi', 'indonesia']],\n",
       " [['bank', 'mandiri'], ['bank', 'mandiri'], ['bank', 'mandiri']],\n",
       " [['nya'],\n",
       "  ['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['ia'],\n",
       "  ['kita'],\n",
       "  ['nya'],\n",
       "  ['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati']],\n",
       " [['<angka>', 'dolar', 'as'], ['<angka>', 'dolar', 'as']],\n",
       " [['jurong', 'engineering', 'limited', 'of', 'singapore'], ['jel']],\n",
       " [['nya'],\n",
       "  ['menko', 'perekonomian', 'boediono'],\n",
       "  ['nya'],\n",
       "  ['boediono'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['pefindo'],\n",
       "  ['trje'],\n",
       "  ['analis', 'pefindo', 'ronald', 'hertanto'],\n",
       "  ['nya'],\n",
       "  ['dia'],\n",
       "  ['trje'],\n",
       "  ['trje'],\n",
       "  ['trje'],\n",
       "  ['nya']],\n",
       " [['adb'],\n",
       "  ['adb'],\n",
       "  ['sendiri'],\n",
       "  ['nya'],\n",
       "  ['direktur', 'pendanaan', 'luar', 'negeri', 'multilateral', 'bappenas'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['plta', 'genyem'],\n",
       "  ['papua'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['adb'],\n",
       "  ['gorontalo'],\n",
       "  ['kita'],\n",
       "  ['nya'],\n",
       "  ['dewo'],\n",
       "  ['sekretaris', 'perusahaan', 'bakrie', 'sumatera', 'plantations', 'tbk'],\n",
       "  ['fitri', 'barnas'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['pt', 'nibung', 'arthamulia']],\n",
       " [['pgas'], ['saham', 'pgas'], ['nya']],\n",
       " [['nya'],\n",
       "  ['dirjen',\n",
       "   'bea',\n",
       "   'dan',\n",
       "   'cukai',\n",
       "   'departemen',\n",
       "   'keuangan',\n",
       "   'anwar',\n",
       "   'suprijad'],\n",
       "  ['anwar', 'suprijad'],\n",
       "  ['anwar'],\n",
       "  ['nya'],\n",
       "  ['kita']],\n",
       " [['lembaga', 'pemeringkat', 'internasional', 'fitch', 'ratings'], ['fitch']],\n",
       " [['dpr'], ['dpr'], ['nya'], ['dia'], ['nya'], ['ia'], ['nya']],\n",
       " [['ai', 'ling', 'ngiam'], ['nya']],\n",
       " [['pt', 'astra', 'otoparts', 'tbk'], ['pt', 'astra', 'otoparts']],\n",
       " [['pt', 'exedy', 'indonesia'], ['pt', 'exedy', 'indonesia']]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in baseline_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['hartadi', 'a', 'sarwono'],\n",
       "  ['ia'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['hartadi'],\n",
       "  ['ia']],\n",
       " [['dirjend',\n",
       "   'industri',\n",
       "   'logam',\n",
       "   'mesin',\n",
       "   'tekstil',\n",
       "   'departemen',\n",
       "   'perindustrian',\n",
       "   'ansari',\n",
       "   'bukhari'],\n",
       "  ['ansari'],\n",
       "  ['ansari']],\n",
       " [['pdb'], ['pdb'], ['pdb']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani'],\n",
       "  ['sri', 'mulyani'],\n",
       "  ['mulyani'],\n",
       "  ['mulyani']],\n",
       " [['direktur', 'aali'], ['santosa'], ['nya']],\n",
       " [['miranda', 's', 'goeltom'], ['miranda'], ['miranda'], ['nya'], ['nya']],\n",
       " [['deputi', 'gubernur', 'senior', 'bi'],\n",
       "  ['miranda', 's', 'goeltom'],\n",
       "  ['miranda'],\n",
       "  ['nya']],\n",
       " [['direktur', 'teknologi', 'dan', 'operasional', 'bank', 'mandiri'],\n",
       "  ['sasmita'],\n",
       "  ['dia'],\n",
       "  ['ia'],\n",
       "  ['nya']],\n",
       " [['bank', 'mandiri'],\n",
       "  ['nya'],\n",
       "  ['kami'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['bank', 'mandiri'],\n",
       "  ['nya']],\n",
       " [['menko', 'perekonomian', 'boediono'], ['nya'], ['boediono'], ['nya']],\n",
       " [['menteri', 'keuangan', 'sri', 'mulyani', 'indrawati'], ['nya'], ['nya']],\n",
       " [['analis', 'pefindo', 'ronald', 'hertanto'], ['nya'], ['dia']],\n",
       " [['trje'], ['trje'], ['trje']],\n",
       " [['jel'], ['jel']],\n",
       " [['adb'], ['adb'], ['adb']],\n",
       " [['direktur', 'pendanaan', 'luar', 'negeri', 'multilateral', 'bappenas'],\n",
       "  ['rm', 'dewo', 'broto', 'joko', 'p'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['nya'],\n",
       "  ['dewo']],\n",
       " [['sekretaris', 'perusahaan', 'bakrie', 'sumatera', 'plantations', 'tbk'],\n",
       "  ['fitri', 'barnas'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['pt', 'nibung', 'arthamulia'], ['pt', 'nibung', 'arthamulia']],\n",
       " [['dpr'], ['dpr']],\n",
       " [['dirjen',\n",
       "   'bea',\n",
       "   'dan',\n",
       "   'cukai',\n",
       "   'departemen',\n",
       "   'keuangan',\n",
       "   'anwar',\n",
       "   'suprijad'],\n",
       "  ['anwar', 'suprijad'],\n",
       "  ['anwar'],\n",
       "  ['nya'],\n",
       "  ['dia'],\n",
       "  ['nya'],\n",
       "  ['ia']],\n",
       " [['indonesia'], ['nya']],\n",
       " [['lembaga', 'pemeringkat', 'internasional', 'fitch', 'ratings'],\n",
       "  ['fitch'],\n",
       "  ['fitch']],\n",
       " [['ai', 'ling', 'ngiam'], ['nya'], ['nya'], ['nya'], ['nya']],\n",
       " [['pt', 'astra', 'otoparts', 'tbk'],\n",
       "  ['nya'],\n",
       "  ['kami'],\n",
       "  ['pt', 'astra', 'otoparts']],\n",
       " [['pt', 'exedy', 'indonesia'],\n",
       "  ['exedy', 'corporation'],\n",
       "  ['pt', 'exedy', 'indonesia'],\n",
       "  ['exedy', 'corporation']],\n",
       " [['sekretaris', 'perusahaan', 'astra', 'otoparts'],\n",
       "  ['kartina', 'rahayu'],\n",
       "  ['dia'],\n",
       "  ['dia'],\n",
       "  ['nya']],\n",
       " [['menkeu', 'sri', 'mulyani', 'indrawati'], ['dia']]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[get_markable_text(b) for b in a] for a in label_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
