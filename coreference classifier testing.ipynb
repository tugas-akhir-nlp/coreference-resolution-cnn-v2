{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.coreference_classifier import CoreferenceClassifierModelBuilder\n",
    "from functools import reduce\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.clusterers import BestFirstClusterer, get_anaphora_scores_by_antecedent, ClosestFirstClusterer\n",
    "from utils.scorers import MUCScorer, B3Scorer\n",
    "from utils.data_structures import UFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>num_words</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1258, 1259, 1955, 1389]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[996, 377, 1156, 212, 26, 1258, 1956, 1183, 14...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[212]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1258, 1259, 1955, 1389, 996, 377, 1156]</td>\n",
       "      <td>[26, 1258, 1956, 1183, 1464, 24, 1156, 62, 422...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1258, 1956, 1183]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1258, 1259, 1955, 1389, 996, 377, 1156, 212, 26]</td>\n",
       "      <td>[1464, 24, 1156, 62, 422, 1218, 24, 1409, 1156...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1464, 24, 1156]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1955, 1389, 996, 377, 1156, 212, 26, 1258, 19...</td>\n",
       "      <td>[62, 422, 1218, 24, 1409, 1156, 874, 342, 212,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[422]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1156, 212, 26, 1258, 1956, 1183, 1464, 24, 11...</td>\n",
       "      <td>[1218, 24, 1409, 1156, 874, 342, 212, 404, 121...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1258, 1259, 1955, 1389]           0  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]   \n",
       "1  1917                     [212]           1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "2  1918        [1258, 1956, 1183]           0  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0]   \n",
       "3  1919          [1464, 24, 1156]           0  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "4  1920                     [422]           0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  num_words  \\\n",
       "0               1                0          4   \n",
       "1               0                0          1   \n",
       "2               1                0          3   \n",
       "3               0                0          3   \n",
       "4               0                0          1   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1258, 1259, 1955, 1389, 996, 377, 1156]   \n",
       "2  [1258, 1259, 1955, 1389, 996, 377, 1156, 212, 26]   \n",
       "3  [1955, 1389, 996, 377, 1156, 212, 26, 1258, 19...   \n",
       "4  [1156, 212, 26, 1258, 1956, 1183, 1464, 24, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [996, 377, 1156, 212, 26, 1258, 1956, 1183, 14...   [0.0, 1.0]  \n",
       "1  [26, 1258, 1956, 1183, 1464, 24, 1156, 62, 422...   [1.0, 0.0]  \n",
       "2  [1464, 24, 1156, 62, 422, 1218, 24, 1409, 1156...   [0.0, 1.0]  \n",
       "3  [62, 422, 1218, 24, 1409, 1156, 874, 342, 212,...   [0.0, 1.0]  \n",
       "4  [1218, 24, 1409, 1156, 874, 342, 212, 404, 121...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markables = get_markable_dataframe(\"data/testing/markables_with_predicted_singleton.csv\", word_vector, idx_by_word)\n",
    "singletons = set(markables[markables['is_singleton'].map(lambda x: True if x[1] > 0 else False)]['id'])\n",
    "markables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1_id</th>\n",
       "      <th>m2_id</th>\n",
       "      <th>is_exact_match</th>\n",
       "      <th>is_words_match</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>is_abbreviation</th>\n",
       "      <th>is_appositive</th>\n",
       "      <th>is_nearest_candidate</th>\n",
       "      <th>sentence_distance</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>markable_distance</th>\n",
       "      <th>is_coreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2245</td>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2245</td>\n",
       "      <td>2247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2245</td>\n",
       "      <td>2248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2245</td>\n",
       "      <td>2249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2245</td>\n",
       "      <td>2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m1_id  m2_id  is_exact_match  is_words_match  is_substring  \\\n",
       "0   2245   2246               0               0             0   \n",
       "1   2245   2247               0               0             0   \n",
       "2   2245   2248               0               0             0   \n",
       "3   2245   2249               0               0             0   \n",
       "4   2245   2250               0               0             0   \n",
       "\n",
       "   is_abbreviation  is_appositive  is_nearest_candidate  sentence_distance  \\\n",
       "0                0              0                     1                  0   \n",
       "1                0              0                     0                  0   \n",
       "2                0              0                     0                  0   \n",
       "3                0              0                     0                  0   \n",
       "4                0              0                     0                  0   \n",
       "\n",
       "   word_distance  markable_distance  is_coreference  \n",
       "0              3                  1               0  \n",
       "1              5                  2               0  \n",
       "2              7                  3               0  \n",
       "3              9                  4               0  \n",
       "4             12                  5               0  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence = 6\n",
    "\n",
    "pairs = pd.read_csv(\"data/testing/mention_pairs.csv\", nrows=250000)\n",
    "pairs = pairs[pairs['sentence_distance'] < max_sentence]\n",
    "\n",
    "label = np.vstack(to_categorical(pairs.is_coreference, num_classes=2))\n",
    "label_chains = ClosestFirstClusterer().get_chains(get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label))\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "def get_data(markable_ids):\n",
    "    indices = reduce(lambda a, b: a + [b], map(lambda a: markables.index[markables['id'] == a].tolist()[0], markable_ids), [])\n",
    "    data = markables.loc[indices]\n",
    "    \n",
    "    data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "    data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "    data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "    data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "    data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "    is_singleton = np.vstack(data.is_singleton)\n",
    "    \n",
    "    return data_text, data_previous_words, data_next_words, data_syntactic, is_singleton\n",
    "\n",
    "def get_pair_data(markable_ids_1, markable_ids_2):\n",
    "    text_1, prev_1, next_1, syntactic_1, is_singleton_1 = get_data(markable_ids_1)\n",
    "    text_2, prev_2, next_2, syntactic_2, is_singleton_2 = get_data(markable_ids_2)\n",
    "    \n",
    "    return text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2\n",
    "\n",
    "def get_relation_data(mention_pairs):\n",
    "    return mention_pairs[['is_exact_match', 'is_words_match', 'is_substring', 'is_abbreviation', 'is_appositive', 'is_nearest_candidate', 'sentence_distance', 'word_distance', 'markable_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUC:  (0.26732673267326734, 0.7297297297297297, 0.391304347826087)\n",
      "B3:  (0.14114949258391882, 0.6940000000000001, 0.2345873372925423)\n"
     ]
    }
   ],
   "source": [
    "baseline_result_file_path = 'baseline/test_result.txt'\n",
    "\n",
    "baseline_ufds = UFDS()\n",
    "\n",
    "for m1, m2 in zip(pairs.m1_id, pairs.m2_id):\n",
    "    baseline_ufds.init_id(m1, m2)\n",
    "    \n",
    "for line in open(baseline_result_file_path, 'r').readlines():\n",
    "    line = line.split(', ')\n",
    "    baseline_ufds.join(int(line[0]), int(line[1]))\n",
    "\n",
    "baseline_chains = baseline_ufds.get_chain_list()\n",
    "\n",
    "print('MUC: ', MUCScorer().get_scores(baseline_chains, label_chains))\n",
    "print('B3: ', B3Scorer().get_scores(baseline_chains, label_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2 = get_pair_data(pairs.m1_id, pairs.m2_id)\n",
    "relation = get_relation_data(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model_1 = load_model('models/coreference_classifiers/words_gilang.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17263/17263 [==============================] - 6s 337us/step\n"
     ]
    }
   ],
   "source": [
    "syntactic_1_pred = words_syntactic_model_1.predict([text_1, text_2], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "predz = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, syntactic_1_pred)\n",
    "predz2 = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, syntactic_1_pred, singletons)\n",
    "labz = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_chains = ClosestFirstClusterer().get_chains(predz, threshold=0.4)\n",
    "pred_chains2 = ClosestFirstClusterer().get_chains(predz2, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.46808510638297873, 0.5945945945945946, 0.5238095238095238)\n",
      "(0.625, 0.5405405405405406, 0.5797101449275363)\n",
      "\n",
      "(0.39356118791602657, 0.5619999999999999, 0.46293505932608897)\n",
      "(0.5800405268490375, 0.5013333333333334, 0.5378226004919506)\n"
     ]
    }
   ],
   "source": [
    "print(MUCScorer().get_scores(pred_chains, lab_chains))\n",
    "print(MUCScorer().get_scores(pred_chains2, lab_chains))\n",
    "print()\n",
    "print(B3Scorer().get_scores(pred_chains, lab_chains))\n",
    "print(B3Scorer().get_scores(pred_chains2, lab_chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2245],\n",
       " [2246],\n",
       " [2247],\n",
       " [2248],\n",
       " [2249],\n",
       " [2250],\n",
       " [2251],\n",
       " [2252],\n",
       " [2253],\n",
       " [2254],\n",
       " [2256],\n",
       " [2257],\n",
       " [2259],\n",
       " [2260],\n",
       " [2261],\n",
       " [2262],\n",
       " [2263],\n",
       " [2264],\n",
       " [2265],\n",
       " [2267],\n",
       " [2268],\n",
       " [2269],\n",
       " [2271],\n",
       " [2272],\n",
       " [2273],\n",
       " [2274],\n",
       " [2275],\n",
       " [2276],\n",
       " [2277],\n",
       " [2278],\n",
       " [2279],\n",
       " [2280],\n",
       " [2281],\n",
       " [2282],\n",
       " [2283],\n",
       " [2284],\n",
       " [2285],\n",
       " [2287],\n",
       " [2288],\n",
       " [2289],\n",
       " [2290],\n",
       " [2291],\n",
       " [2292],\n",
       " [2293],\n",
       " [2294],\n",
       " [2295],\n",
       " [2296],\n",
       " [2297],\n",
       " [2298],\n",
       " [2299],\n",
       " [2300],\n",
       " [2301],\n",
       " [2302],\n",
       " [2255, 2258, 2266, 2270, 2286, 2303],\n",
       " [2304],\n",
       " [2305],\n",
       " [2306],\n",
       " [2307],\n",
       " [2308],\n",
       " [2309],\n",
       " [2310],\n",
       " [2312],\n",
       " [2313],\n",
       " [2314],\n",
       " [2315],\n",
       " [2317],\n",
       " [2318],\n",
       " [2319],\n",
       " [2320],\n",
       " [2321],\n",
       " [2322],\n",
       " [2311, 2316, 2323],\n",
       " [2324],\n",
       " [2325],\n",
       " [2326],\n",
       " [2327],\n",
       " [2328],\n",
       " [2329],\n",
       " [2331],\n",
       " [2332],\n",
       " [2334],\n",
       " [2335],\n",
       " [2336],\n",
       " [2338],\n",
       " [2339],\n",
       " [2340],\n",
       " [2341],\n",
       " [2342],\n",
       " [2344],\n",
       " [2345],\n",
       " [2346],\n",
       " [2333, 2343, 2347],\n",
       " [2348],\n",
       " [2349],\n",
       " [2350],\n",
       " [2351],\n",
       " [2352],\n",
       " [2353],\n",
       " [2354],\n",
       " [2355],\n",
       " [2356],\n",
       " [2357],\n",
       " [2358],\n",
       " [2359],\n",
       " [2360],\n",
       " [2361],\n",
       " [2362],\n",
       " [2363],\n",
       " [2364],\n",
       " [2365],\n",
       " [2366],\n",
       " [2368],\n",
       " [2369],\n",
       " [2370],\n",
       " [2371],\n",
       " [2372],\n",
       " [2373],\n",
       " [2374],\n",
       " [2330, 2337, 2367, 2375],\n",
       " [2376],\n",
       " [2377],\n",
       " [2378],\n",
       " [2379],\n",
       " [2380],\n",
       " [2381],\n",
       " [2382],\n",
       " [2383],\n",
       " [2384],\n",
       " [2385],\n",
       " [2386],\n",
       " [2387],\n",
       " [2388],\n",
       " [2389],\n",
       " [2390],\n",
       " [2391],\n",
       " [2392],\n",
       " [2395],\n",
       " [2396],\n",
       " [2397],\n",
       " [2398],\n",
       " [2393, 2394, 2399],\n",
       " [2400],\n",
       " [2401],\n",
       " [2402],\n",
       " [2403],\n",
       " [2404],\n",
       " [2405],\n",
       " [2406],\n",
       " [2407],\n",
       " [2408],\n",
       " [2409],\n",
       " [2410],\n",
       " [2411],\n",
       " [2412],\n",
       " [2413],\n",
       " [2414],\n",
       " [2415],\n",
       " [2416],\n",
       " [2417],\n",
       " [2418],\n",
       " [2419],\n",
       " [2420],\n",
       " [2421],\n",
       " [2422],\n",
       " [2423],\n",
       " [2424],\n",
       " [2425],\n",
       " [2427],\n",
       " [2428],\n",
       " [2429],\n",
       " [2430],\n",
       " [2431],\n",
       " [2432],\n",
       " [2433],\n",
       " [2434],\n",
       " [2435],\n",
       " [2437],\n",
       " [2438],\n",
       " [2439],\n",
       " [2440],\n",
       " [2441],\n",
       " [2442],\n",
       " [2443],\n",
       " [2444],\n",
       " [2445],\n",
       " [2446],\n",
       " [2447],\n",
       " [2448],\n",
       " [2449],\n",
       " [2451],\n",
       " [2452],\n",
       " [2453],\n",
       " [2454],\n",
       " [2455],\n",
       " [2456],\n",
       " [2457],\n",
       " [2458],\n",
       " [2459],\n",
       " [2460],\n",
       " [2461],\n",
       " [2462],\n",
       " [2463],\n",
       " [2465],\n",
       " [2426, 2436, 2450, 2464, 2466],\n",
       " [2467],\n",
       " [2468],\n",
       " [2471],\n",
       " [2472],\n",
       " [2473],\n",
       " [2474],\n",
       " [2475],\n",
       " [2476],\n",
       " [2477],\n",
       " [2478],\n",
       " [2479],\n",
       " [2481],\n",
       " [2482],\n",
       " [2483],\n",
       " [2484],\n",
       " [2485],\n",
       " [2486],\n",
       " [2487],\n",
       " [2469, 2470, 2480, 2488],\n",
       " [2489],\n",
       " [2490],\n",
       " [2491],\n",
       " [2492],\n",
       " [2493],\n",
       " [2494],\n",
       " [2495],\n",
       " [2496],\n",
       " [2497],\n",
       " [2498],\n",
       " [2499],\n",
       " [2500],\n",
       " [2501],\n",
       " [2502],\n",
       " [2503],\n",
       " [2504],\n",
       " [2505],\n",
       " [2506],\n",
       " [2507],\n",
       " [2508],\n",
       " [2509],\n",
       " [2511],\n",
       " [2512],\n",
       " [2513],\n",
       " [2514],\n",
       " [2515],\n",
       " [2516],\n",
       " [2518],\n",
       " [2519],\n",
       " [2521],\n",
       " [2522],\n",
       " [2523],\n",
       " [2526],\n",
       " [2527],\n",
       " [2529],\n",
       " [2531],\n",
       " [2532],\n",
       " [2533],\n",
       " [2534],\n",
       " [2536],\n",
       " [2537],\n",
       " [2538],\n",
       " [2539],\n",
       " [2540],\n",
       " [2541],\n",
       " [2542],\n",
       " [2543],\n",
       " [2544],\n",
       " [2524, 2525, 2528, 2535, 2545],\n",
       " [2547],\n",
       " [2548],\n",
       " [2549],\n",
       " [2550],\n",
       " [2551],\n",
       " [2552],\n",
       " [2553],\n",
       " [2510, 2517, 2520, 2530, 2546, 2554],\n",
       " [2555],\n",
       " [2556],\n",
       " [2557],\n",
       " [2558],\n",
       " [2559],\n",
       " [2560],\n",
       " [2561],\n",
       " [2562],\n",
       " [2563],\n",
       " [2564],\n",
       " [2566],\n",
       " [2567],\n",
       " [2568],\n",
       " [2569],\n",
       " [2570],\n",
       " [2571],\n",
       " [2572],\n",
       " [2573],\n",
       " [2574],\n",
       " [2575],\n",
       " [2576],\n",
       " [2577],\n",
       " [2578],\n",
       " [2579],\n",
       " [2580],\n",
       " [2581],\n",
       " [2582],\n",
       " [2583],\n",
       " [2584],\n",
       " [2585],\n",
       " [2586],\n",
       " [2587],\n",
       " [2588],\n",
       " [2589],\n",
       " [2590],\n",
       " [2591],\n",
       " [2565, 2592],\n",
       " [2593],\n",
       " [2594],\n",
       " [2595],\n",
       " [2596],\n",
       " [2597],\n",
       " [2598],\n",
       " [2599],\n",
       " [2600],\n",
       " [2601],\n",
       " [2602],\n",
       " [2604],\n",
       " [2605],\n",
       " [2606],\n",
       " [2607],\n",
       " [2608],\n",
       " [2609],\n",
       " [2610],\n",
       " [2611],\n",
       " [2612],\n",
       " [2613],\n",
       " [2614],\n",
       " [2615],\n",
       " [2616],\n",
       " [2617],\n",
       " [2618],\n",
       " [2619],\n",
       " [2622],\n",
       " [2623],\n",
       " [2624],\n",
       " [2625],\n",
       " [2626],\n",
       " [2627],\n",
       " [2628],\n",
       " [2629],\n",
       " [2603, 2620, 2621, 2630],\n",
       " [2631],\n",
       " [2632],\n",
       " [2633],\n",
       " [2634],\n",
       " [2635],\n",
       " [2636],\n",
       " [2637],\n",
       " [2638],\n",
       " [2639],\n",
       " [2640],\n",
       " [2641],\n",
       " [2642],\n",
       " [2643],\n",
       " [2644],\n",
       " [2645],\n",
       " [2646],\n",
       " [2647],\n",
       " [2648],\n",
       " [2649],\n",
       " [2650],\n",
       " [2651],\n",
       " [2652],\n",
       " [2653],\n",
       " [2654],\n",
       " [2656],\n",
       " [2657],\n",
       " [2658],\n",
       " [2659],\n",
       " [2660],\n",
       " [2661],\n",
       " [2662],\n",
       " [2663],\n",
       " [2664],\n",
       " [2665],\n",
       " [2666],\n",
       " [2667],\n",
       " [2670],\n",
       " [2671],\n",
       " [2668, 2669, 2672],\n",
       " [2673],\n",
       " [2655, 2677]]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TA",
   "language": "python",
   "name": "ta-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
