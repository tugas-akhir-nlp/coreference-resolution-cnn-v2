{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.coreference_classifier import CoreferenceClassifierModelBuilder\n",
    "from functools import reduce\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.clusterers import BestFirstClusterer, get_anaphora_scores_by_antecedent, ClosestFirstClusterer\n",
    "from utils.scorers import MUCScorer, B3Scorer, AverageScorer\n",
    "from utils.data_structures import UFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]   \n",
       "1  1917                     [213]           1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  1918        [1263, 1969, 1188]           0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "4  1920                     [424]           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [0.0, 1.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [0.0, 1.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markables = get_markable_dataframe(\"data/testing/markables_with_predicted_singleton.csv\", word_vector, idx_by_word)\n",
    "singletons = set(markables[markables['is_singleton'].map(lambda x: True if x[1] > 0 else False)]['id'])\n",
    "markables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1_id</th>\n",
       "      <th>m2_id</th>\n",
       "      <th>is_exact_match</th>\n",
       "      <th>is_words_match</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>is_abbreviation</th>\n",
       "      <th>is_appositive</th>\n",
       "      <th>is_nearest_candidate</th>\n",
       "      <th>sentence_distance</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>markable_distance</th>\n",
       "      <th>is_coreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1916</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m1_id  m2_id  is_exact_match  is_words_match  is_substring  \\\n",
       "0   1916   1917               0               0             0   \n",
       "1   1916   1918               0               0             0   \n",
       "2   1916   1919               0               0             0   \n",
       "3   1916   1920               0               0             0   \n",
       "4   1916   1921               0               0             0   \n",
       "\n",
       "   is_abbreviation  is_appositive  is_nearest_candidate  sentence_distance  \\\n",
       "0                0              0                     1                  0   \n",
       "1                0              0                     0                  0   \n",
       "2                0              0                     0                  0   \n",
       "3                0              0                     0                  0   \n",
       "4                0              0                     0                  0   \n",
       "\n",
       "   word_distance  markable_distance  is_coreference  \n",
       "0              3                  1               1  \n",
       "1              5                  2               0  \n",
       "2              8                  3               0  \n",
       "3             12                  4               0  \n",
       "4             13                  5               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.read_csv(\"data/testing/mention_pairs.csv\")\n",
    "\n",
    "label = np.vstack(to_categorical(pairs.is_coreference, num_classes=2))\n",
    "label_chains = ClosestFirstClusterer().get_chains(get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label))\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "def get_data(markable_ids):\n",
    "    indices = reduce(lambda a, b: a + [b], map(lambda a: markables.index[markables['id'] == a].tolist()[0], markable_ids), [])\n",
    "    data = markables.loc[indices]\n",
    "    \n",
    "    data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "    data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "    data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "    data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "    data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "    is_singleton = np.vstack(data.is_singleton)\n",
    "    \n",
    "    return data_text, data_previous_words, data_next_words, data_syntactic, is_singleton\n",
    "\n",
    "def get_pair_data(markable_ids_1, markable_ids_2):\n",
    "    text_1, prev_1, next_1, syntactic_1, is_singleton_1 = get_data(markable_ids_1)\n",
    "    text_2, prev_2, next_2, syntactic_2, is_singleton_2 = get_data(markable_ids_2)\n",
    "    \n",
    "    return text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2\n",
    "\n",
    "def get_relation_data(mention_pairs):\n",
    "    return mention_pairs[['is_exact_match', 'is_words_match', 'is_substring', 'is_abbreviation', 'is_appositive', 'is_nearest_candidate', 'sentence_distance', 'word_distance', 'markable_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUC:  (0.5544554455445545, 0.7272727272727273, 0.6292134831460674)\n",
      "B3:  (0.3124361294443262, 0.6732829670329671, 0.4268110965737344)\n",
      "Average:  (0.5280122898599009, 0.5280122898599009, 0.5280122898599009)\n"
     ]
    }
   ],
   "source": [
    "baseline_result_file_path = 'baseline/test_result.txt'\n",
    "\n",
    "baseline_ufds = UFDS()\n",
    "\n",
    "for m1, m2 in zip(pairs.m1_id, pairs.m2_id):\n",
    "    baseline_ufds.init_id(m1, m2)\n",
    "    \n",
    "for line in open(baseline_result_file_path, 'r').readlines():\n",
    "    line = line.split(', ')\n",
    "    baseline_ufds.join(int(line[0]), int(line[1]))\n",
    "\n",
    "baseline_chains = baseline_ufds.get_chain_list()\n",
    "\n",
    "print('MUC: ', MUCScorer().get_scores(baseline_chains, label_chains))\n",
    "print('B3: ', B3Scorer().get_scores(baseline_chains, label_chains))\n",
    "print('Average: ', AverageScorer([MUCScorer(), B3Scorer()]).get_scores(baseline_chains, label_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2 = get_pair_data(pairs.m1_id, pairs.m2_id)\n",
    "relation = get_relation_data(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "def get_model(features, data_generation, epoch):\n",
    "    name = '_'.join([*features, data_generation, str(epoch)])\n",
    "    \n",
    "    if name not in models:\n",
    "        models[name] = load_model(f'models/coreference_classifiers/{name}.model')\n",
    "    \n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_thresholds = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "thresholds = [base * multiplier for base in base_thresholds for multiplier in range(1, 10)]\n",
    "\n",
    "muc_scorer = MUCScorer()\n",
    "b3_scorer = B3Scorer()\n",
    "average_scorer = AverageScorer([muc_scorer, b3_scorer])\n",
    "\n",
    "def get_sorted_scores(clusterer, pred):\n",
    "    scores = [] # will be a tuple (average_f1, (prec_muc, rec_muc, f1_muc), (prec_b3, rec_b3, f1_b3), threshold)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predicted_chains = clusterer.get_chains(pred, threshold)\n",
    "        \n",
    "#         avg_f1 = average_scorer.get_scores(predicted_chains, label_chains)[2]\n",
    "        muc = muc_scorer.get_scores(predicted_chains, label_chains)\n",
    "        b3 = b3_scorer.get_scores(predicted_chains, label_chains)\n",
    "        avg_f1 = (muc[2] + b3[2]) / 2\n",
    "        \n",
    "        scores.append((avg_f1, muc, b3, threshold))\n",
    "    \n",
    "    return sorted(scores, reverse=True)\n",
    "\n",
    "def evaluate(features, data_generation, epoch):\n",
    "    model = get_model(features, data_generation, epoch)\n",
    "    \n",
    "    test_features = []\n",
    "    if 'words' in features:\n",
    "        test_features.extend([text_1, text_2])\n",
    "    if 'context' in features:\n",
    "        test_features.extend([prev_1, prev_2, next_1, next_2])\n",
    "    if 'syntactic' in features:\n",
    "        test_features.extend([syntactic_1, syntactic_2, relation])\n",
    "    \n",
    "    print('getting anaphora scores by antecedent dict')\n",
    "    raw_pred = model.predict(test_features, verbose=1)\n",
    "    pred_without_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred)\n",
    "    pred_with_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred, singletons)\n",
    "    \n",
    "    print('get sorted_scores_without_sc_closest')\n",
    "    sorted_scores_without_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, closest-first:', sorted_scores_without_sc_closest[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_closest')\n",
    "    sorted_scores_with_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, closest-first:', sorted_scores_with_sc_closest[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_without_sc_best')\n",
    "    sorted_scores_without_sc_best = get_sorted_scores(BestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, best-first:', sorted_scores_without_sc_best[0])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_best')\n",
    "    sorted_scores_with_sc_best = get_sorted_scores(BestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, best-first:', sorted_scores_with_sc_best[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 6s 235us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.35413218980519395, (0.4482758620689655, 0.33766233766233766, 0.3851851851851852), (0.3568181818181818, 0.2951694139194139, 0.3230791944252027), 0.05)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5324111982788836, (0.5612244897959183, 0.7142857142857143, 0.6285714285714286), (0.32605634287050217, 0.6589514652014654, 0.4362509679863387), 2e-05)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.3675733338394137, (0.46551724137931033, 0.35064935064935066, 0.4), (0.3675555555555555, 0.3079899267399267, 0.33514666767882745), 0.05)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5155418802575614, (0.5408163265306123, 0.6883116883116883, 0.6057142857142858), (0.32063771997982526, 0.6317078754578755, 0.4253694748008371), 2e-05)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 210us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.40764365653432477, (0.5370370370370371, 0.37662337662337664, 0.44274809160305345), (0.43550514800514806, 0.32548076923076924, 0.37253922146559615), 0.02)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.5289191930872699, (0.5353535353535354, 0.6883116883116883, 0.6022727272727273), (0.3545748742782641, 0.6369963369963371, 0.45556565890181244), 1e-05)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.44239623560721375, (0.4375, 0.5454545454545454, 0.48554913294797686), (0.33154971643343734, 0.5016712454212454, 0.3992433382664507), 0.0005)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.5225860893208769, (0.5360824742268041, 0.6753246753246753, 0.5977011494252873), (0.34993231406274883, 0.6203983516483518, 0.44747102921646664), 2e-05)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 220us/sample\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: (0.3683888682725824, (0.5897435897435898, 0.2987012987012987, 0.39655172413793105), (0.5307017543859649, 0.25036630036630036, 0.3402260124072337), 0.06)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: (0.505133139932475, (0.5675675675675675, 0.5454545454545454, 0.5562913907284768), (0.4346938227257376, 0.4750457875457875, 0.4539748891364731), 1e-05)\n",
      "\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: (0.3785229305096004, (0.5531914893617021, 0.33766233766233766, 0.41935483870967744), (0.4143229166666667, 0.28498168498168497, 0.3376910223095233), 0.02)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: (0.4709314903261924, (0.5405405405405406, 0.5194805194805194, 0.5298013245033113), (0.3735162180814354, 0.459478021978022, 0.4120616561490735), 1e-05)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gilang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'syntactic'], 'budi', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[get_markable_text(b) for b in a] for a in pred_chains2 if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[get_markable_text(b) for b in a] for a in baseline_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[get_markable_text(b) for b in a] for a in label_chains if len(a) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
