{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.coreference_classifier import CoreferenceClassifierModelBuilder\n",
    "from functools import reduce\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.clusterers import BestFirstClusterer, get_anaphora_scores_by_antecedent, ClosestFirstClusterer\n",
    "from utils.scorers import MUCScorer, B3Scorer, AverageScorer\n",
    "from utils.data_structures import UFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>[1263, 1264, 1968, 1395]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>[213]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161]</td>\n",
       "      <td>[27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1918</td>\n",
       "      <td>[1263, 1969, 1188]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]</td>\n",
       "      <td>[1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1919</td>\n",
       "      <td>[1470, 25, 1161]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...</td>\n",
       "      <td>[63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1920</td>\n",
       "      <td>[424]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...</td>\n",
       "      <td>[1223, 25, 1415, 1161, 876, 344, 213, 406, 122...</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                      text  is_pronoun                     entity_type  \\\n",
       "0  1916  [1263, 1264, 1968, 1395]           0  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0]   \n",
       "1  1917                     [213]           1  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]   \n",
       "2  1918        [1263, 1969, 1188]           0  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  1919          [1470, 25, 1161]           0  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]   \n",
       "4  1920                     [424]           0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "\n",
       "   is_proper_name  is_first_person  \\\n",
       "0               1                0   \n",
       "1               0                0   \n",
       "2               1                0   \n",
       "3               0                0   \n",
       "4               0                0   \n",
       "\n",
       "                                      previous_words  \\\n",
       "0                                                 []   \n",
       "1           [1263, 1264, 1968, 1395, 999, 379, 1161]   \n",
       "2  [1263, 1264, 1968, 1395, 999, 379, 1161, 213, 27]   \n",
       "3  [1968, 1395, 999, 379, 1161, 213, 27, 1263, 19...   \n",
       "4  [1161, 213, 27, 1263, 1969, 1188, 1470, 25, 11...   \n",
       "\n",
       "                                          next_words is_singleton  \n",
       "0  [999, 379, 1161, 213, 27, 1263, 1969, 1188, 14...   [0.0, 1.0]  \n",
       "1  [27, 1263, 1969, 1188, 1470, 25, 1161, 63, 424...   [1.0, 0.0]  \n",
       "2  [1470, 25, 1161, 63, 424, 1223, 25, 1415, 1161...   [0.0, 1.0]  \n",
       "3  [63, 424, 1223, 25, 1415, 1161, 876, 344, 213,...   [0.0, 1.0]  \n",
       "4  [1223, 25, 1415, 1161, 876, 344, 213, 406, 122...   [0.0, 1.0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markables = get_markable_dataframe(\"data/testing/markables_with_predicted_singleton.csv\", word_vector, idx_by_word)\n",
    "singletons = set(markables[markables['is_singleton'].map(lambda x: True if x[1] > 0 else False)]['id'])\n",
    "markables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1_id</th>\n",
       "      <th>m2_id</th>\n",
       "      <th>is_exact_match</th>\n",
       "      <th>is_words_match</th>\n",
       "      <th>is_substring</th>\n",
       "      <th>is_abbreviation</th>\n",
       "      <th>is_appositive</th>\n",
       "      <th>is_nearest_candidate</th>\n",
       "      <th>sentence_distance</th>\n",
       "      <th>word_distance</th>\n",
       "      <th>markable_distance</th>\n",
       "      <th>is_coreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1916</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1916</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1916</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1916</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m1_id  m2_id  is_exact_match  is_words_match  is_substring  \\\n",
       "0   1916   1917               0               0             0   \n",
       "1   1916   1918               0               0             0   \n",
       "2   1916   1919               0               0             0   \n",
       "3   1916   1920               0               0             0   \n",
       "4   1916   1921               0               0             0   \n",
       "\n",
       "   is_abbreviation  is_appositive  is_nearest_candidate  sentence_distance  \\\n",
       "0                0              0                     1                  0   \n",
       "1                0              0                     0                  0   \n",
       "2                0              0                     0                  0   \n",
       "3                0              0                     0                  0   \n",
       "4                0              0                     0                  0   \n",
       "\n",
       "   word_distance  markable_distance  is_coreference  \n",
       "0              3                  1               1  \n",
       "1              5                  2               0  \n",
       "2              8                  3               0  \n",
       "3             12                  4               0  \n",
       "4             13                  5               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = pd.read_csv(\"data/testing/mention_pairs.csv\")\n",
    "\n",
    "label = np.vstack(to_categorical(pairs.is_coreference, num_classes=2))\n",
    "label_chains = ClosestFirstClusterer().get_chains(get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, label))\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "def get_data(markable_ids):\n",
    "    indices = reduce(lambda a, b: a + [b], map(lambda a: markables.index[markables['id'] == a].tolist()[0], markable_ids), [])\n",
    "    data = markables.loc[indices]\n",
    "    \n",
    "    data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "    data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "    data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "    data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "    data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "    is_singleton = np.vstack(data.is_singleton)\n",
    "    \n",
    "    return data_text, data_previous_words, data_next_words, data_syntactic, is_singleton\n",
    "\n",
    "def get_pair_data(markable_ids_1, markable_ids_2):\n",
    "    text_1, prev_1, next_1, syntactic_1, is_singleton_1 = get_data(markable_ids_1)\n",
    "    text_2, prev_2, next_2, syntactic_2, is_singleton_2 = get_data(markable_ids_2)\n",
    "    \n",
    "    return text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2\n",
    "\n",
    "def get_relation_data(mention_pairs):\n",
    "    return mention_pairs[['is_exact_match', 'is_words_match', 'is_substring', 'is_abbreviation', 'is_appositive', 'is_nearest_candidate', 'sentence_distance', 'word_distance', 'markable_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUC:  (0.5544554455445545, 0.7272727272727273, 0.6292134831460674)\n",
      "B3:  (0.3124361294443262, 0.6732829670329671, 0.4268110965737344)\n",
      "Average:  (0.5280122898599009, 0.5280122898599009, 0.5280122898599009)\n"
     ]
    }
   ],
   "source": [
    "baseline_result_file_path = 'baseline/suherik_and_purwarianti/test_result.txt'\n",
    "\n",
    "baseline_ufds = UFDS()\n",
    "\n",
    "for m1, m2 in zip(pairs.m1_id, pairs.m2_id):\n",
    "    baseline_ufds.init_id(m1, m2)\n",
    "    \n",
    "for line in open(baseline_result_file_path, 'r').readlines():\n",
    "    line = line.split(', ')\n",
    "    baseline_ufds.join(int(line[0]), int(line[1]))\n",
    "\n",
    "baseline_chains = baseline_ufds.get_chain_list()\n",
    "\n",
    "print('MUC: ', MUCScorer().get_scores(baseline_chains, label_chains))\n",
    "print('B3: ', B3Scorer().get_scores(baseline_chains, label_chains))\n",
    "print('Average: ', AverageScorer([MUCScorer(), B3Scorer()]).get_scores(baseline_chains, label_chains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, is_singleton_1, is_singleton_2 = get_pair_data(pairs.m1_id, pairs.m2_id)\n",
    "relation = get_relation_data(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "def get_model(features, data_generation, epoch):\n",
    "    name = '_'.join([*features, data_generation, str(epoch)])\n",
    "    \n",
    "    if name not in models:\n",
    "        models[name] = load_model(f'models/coreference_classifiers/{name}.model')\n",
    "    \n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_thresholds = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "thresholds = [0] + [base * multiplier for base in base_thresholds for multiplier in range(1, 10)]\n",
    "\n",
    "muc_scorer = MUCScorer()\n",
    "b3_scorer = B3Scorer()\n",
    "average_scorer = AverageScorer([muc_scorer, b3_scorer])\n",
    "\n",
    "def get_sorted_scores(clusterer, pred):\n",
    "    scores = [] # will be a tuple (average_f1, (prec_muc, rec_muc, f1_muc), (prec_b3, rec_b3, f1_b3), threshold)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predicted_chains = clusterer.get_chains(pred, threshold)\n",
    "        \n",
    "#         avg_f1 = average_scorer.get_scores(predicted_chains, label_chains)[2]\n",
    "        muc = muc_scorer.get_scores(predicted_chains, label_chains)\n",
    "        b3 = b3_scorer.get_scores(predicted_chains, label_chains)\n",
    "        avg_f1 = (muc[2] + b3[2]) / 2\n",
    "        \n",
    "        scores.append((avg_f1, muc, b3, threshold))\n",
    "    \n",
    "    return sorted(scores, reverse=True)\n",
    "\n",
    "def reorder_score(score):\n",
    "    avg_f1, muc, b3, threshold = score\n",
    "    return muc, b3, avg_f1, threshold\n",
    "\n",
    "def evaluate(features, data_generation, epoch):\n",
    "    model = get_model(features, data_generation, epoch)\n",
    "    \n",
    "    test_features = []\n",
    "    if 'words' in features:\n",
    "        test_features.extend([text_1, text_2])\n",
    "    if 'context' in features:\n",
    "        test_features.extend([prev_1, prev_2, next_1, next_2])\n",
    "    if 'syntactic' in features:\n",
    "        test_features.extend([syntactic_1, syntactic_2, relation])\n",
    "    \n",
    "    print('getting anaphora scores by antecedent dict')\n",
    "    raw_pred = model.predict(test_features, verbose=1)\n",
    "    pred_without_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred)\n",
    "    pred_with_singleton_classifier = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred, singletons)\n",
    "    \n",
    "    print('get sorted_scores_without_sc_best')\n",
    "    sorted_scores_without_sc_best = get_sorted_scores(BestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, best-first:', reorder_score(sorted_scores_without_sc_best[0]))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_without_sc_closest')\n",
    "    sorted_scores_without_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_without_singleton_classifier)\n",
    "    print('Without singleton classifier, closest-first:', reorder_score(sorted_scores_without_sc_closest[0]))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_best')\n",
    "    sorted_scores_with_sc_best = get_sorted_scores(BestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, best-first:', reorder_score(sorted_scores_with_sc_best[0]))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('get sorted_scores_with_sc_closest')\n",
    "    sorted_scores_with_sc_closest = get_sorted_scores(ClosestFirstClusterer(), pred_with_singleton_classifier)\n",
    "    print('With singleton classifier, closest-first:', reorder_score(sorted_scores_with_sc_closest[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 10:40:33.016038 139724918880064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0422 10:40:33.021682 139724918880064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0422 10:40:33.022759 139724918880064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0422 10:40:33.048361 139724918880064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0422 10:40:33.049423 139724918880064 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 7s 295us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.625, 0.6493506493506493, 0.6369426751592356), (0.5052121212121212, 0.6059752747252747, 0.5510250657366206), 0.5939838704479281, 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.6125, 0.6363636363636364, 0.6242038216560509), (0.4927121212121212, 0.5899496336996337, 0.5369642625866148), 0.5805840421213329, 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.5977011494252874, 0.6753246753246753, 0.6341463414634148), (0.45476426481099375, 0.6173992673992673, 0.5237468268574018), 0.5789465841604082, 0.09)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.6376811594202898, 0.5714285714285714, 0.6027397260273972), (0.5334075100929033, 0.5156364468864468, 0.5243714553941523), 0.5635555907107748, 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 7s 305us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.6631578947368421, 0.8181818181818182, 0.7325581395348837), (0.48990662115662115, 0.7725045787545787, 0.5995750164958862), 0.6660665780153849, 0.2)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.6210526315789474, 0.7662337662337663, 0.686046511627907), (0.46143828623167465, 0.7100045787545787, 0.5593500218058001), 0.6226982667168535, 0.2)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.6986301369863014, 0.6623376623376623, 0.68), (0.5461981566820278, 0.6061584249084249, 0.5746183423282252), 0.6273091711641126, 0.2)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.684931506849315, 0.6493506493506493, 0.6666666666666666), (0.5372375832053252, 0.5805173992673993, 0.5580395873541433), 0.612353127010405, 0.2)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0423 13:30:55.572289 139771389228864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0423 13:30:55.575779 139771389228864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0423 13:30:55.576625 139771389228864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0423 13:30:55.591617 139771389228864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0423 13:30:55.592465 139771389228864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 5s 205us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.7297297297297297, 0.7012987012987013, 0.7152317880794701), (0.5996616541353383, 0.649290293040293, 0.6234899461409118), 0.6693608671101909, 0.2)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.7230769230769231, 0.6103896103896104, 0.6619718309859155), (0.6229617604617604, 0.5420558608058609, 0.579699512096331), 0.6208356715411232, 0.30000000000000004)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.7666666666666667, 0.5974025974025974, 0.6715328467153285), (0.6473176612417119, 0.5378891941391941, 0.5875517401482988), 0.6295422934318137, 0.2)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.7636363636363637, 0.5454545454545454, 0.6363636363636364), (0.6526544401544402, 0.4713598901098902, 0.5473864823744434), 0.5918750593690398, 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'budi', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gilang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0421 16:02:50.019941 140507069343552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0421 16:02:50.025677 140507069343552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0421 16:02:50.026860 140507069343552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0421 16:02:50.052691 140507069343552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:96: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0421 16:02:50.053841 140507069343552 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 7s 301us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.5740740740740741, 0.8051948051948052, 0.6702702702702704), (0.3637670291213599, 0.7611950549450549, 0.492279104586934), 0.5812746874286022, 0.5)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.5092592592592593, 0.7142857142857143, 0.5945945945945946), (0.3512658945992279, 0.6641483516483516, 0.45950244592388584), 0.5270485202592402, 0.5)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.627906976744186, 0.7012987012987013, 0.6625766871165645), (0.4442493590551843, 0.6406364468864469, 0.5246678117789049), 0.5936222494477347, 0.5)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.5934065934065934, 0.7012987012987013, 0.6428571428571428), (0.3973474827641494, 0.6486492673992673, 0.49281062021969335), 0.5678338815384181, 0.4)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 8s 352us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.6428571428571429, 0.7012987012987013, 0.6708074534161491), (0.4756504013785567, 0.6373397435897435, 0.544750384760329), 0.607778919088239, 0.6000000000000001)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.6190476190476191, 0.6753246753246753, 0.6459627329192547), (0.4956375442739079, 0.6141025641025641, 0.5485469697033762), 0.5972548513113154, 0.6000000000000001)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.6714285714285714, 0.6103896103896104, 0.6394557823129251), (0.5435910832462556, 0.5352106227106227, 0.5393683019922841), 0.5894120421526046, 0.6000000000000001)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.6428571428571429, 0.5844155844155844, 0.6122448979591837), (0.5390109890109891, 0.5174679487179488, 0.528019822940403), 0.5701323604497933, 0.6000000000000001)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 8s 333us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.5454545454545454, 0.8571428571428571, 0.6666666666666665), (0.36443805818805813, 0.8163690476190477, 0.5039196478679079), 0.5852931572672873, 0.4)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.5617977528089888, 0.6493506493506493, 0.6024096385542169), (0.43300238408934066, 0.5999542124542124, 0.5029864859886461), 0.5526980622714315, 0.8)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.6022727272727273, 0.6883116883116883, 0.6424242424242423), (0.4506319811875368, 0.6214056776556777, 0.5224168560371731), 0.5824205492307077, 0.4)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.5806451612903226, 0.7012987012987013, 0.6352941176470589), (0.3904495654495655, 0.6528159340659341, 0.48864205304013175), 0.5619680853435953, 0.2)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'gilang', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 8s 339us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.35384615384615387, 0.2987012987012987, 0.32394366197183094), (0.35493827160493824, 0.2496794871794872, 0.2931465520062304), 0.3085451069890307, 0.7000000000000001)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.24615384615384617, 0.2077922077922078, 0.22535211267605634), (0.29954954954954954, 0.1980769230769231, 0.23846743028235215), 0.23190977147920425, 0.7000000000000001)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.5747126436781609, 0.6493506493506493, 0.6097560975609756), (0.4032904202715524, 0.5853479853479854, 0.4775562706734287), 0.5436561841172022, 0.5)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.5544554455445545, 0.7272727272727273, 0.6292134831460674), (0.3326109076109076, 0.6758928571428572, 0.4458274614709137), 0.5375204723084905, 5e-05)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 8s 356us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.3867924528301887, 0.5324675324675324, 0.4480874316939891), (0.30092681367849156, 0.4868360805860806, 0.37194448121668316), 0.4100159564553362, 0.9)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.19811320754716982, 0.2727272727272727, 0.22950819672131148), (0.23658503401360545, 0.2870650183150183, 0.259391885172786), 0.24445004094704875, 0.9)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.5578947368421052, 0.6883116883116883, 0.616279069767442), (0.36723939777037123, 0.6342261904761904, 0.4651439789328629), 0.5407115243501525, 0.2)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.5591397849462365, 0.6753246753246753, 0.6117647058823529), (0.38097728230471595, 0.6296474358974359, 0.4747189824627964), 0.5432418441725746, 0.30000000000000004)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting anaphora scores by antecedent dict\n",
      "23689/23689==============================] - 8s 339us/sample\n",
      "get sorted_scores_without_sc_best\n",
      "Without singleton classifier, best-first: ((0.38392857142857145, 0.5584415584415584, 0.455026455026455), (0.31114030896639594, 0.5032967032967033, 0.3845500374064958), 0.41978824621647537, 0.6000000000000001)\n",
      "\n",
      "get sorted_scores_without_sc_closest\n",
      "Without singleton classifier, closest-first: ((0.2, 0.24675324675324675, 0.22093023255813954), (0.24140786749482399, 0.24919871794871792, 0.24524143322722294), 0.23308583289268126, 0.9)\n",
      "\n",
      "get sorted_scores_with_sc_best\n",
      "With singleton classifier, best-first: ((0.6567164179104478, 0.5714285714285714, 0.6111111111111112), (0.5719426406926407, 0.5035027472527472, 0.5355449827348352), 0.5733280469229731, 0.4)\n",
      "\n",
      "get sorted_scores_with_sc_closest\n",
      "With singleton classifier, closest-first: ((0.6125, 0.6363636363636364, 0.6242038216560509), (0.46921263554926923, 0.5863782051282052, 0.5212930094775621), 0.5727484155668066, 0.2)\n"
     ]
    }
   ],
   "source": [
    "evaluate(['words', 'context', 'syntactic'], 'soon', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markable_text(idx):\n",
    "    return [word_by_idx[x] for x in markables[markables['id'] == idx].text.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23689/23689==============================] - 5s 192us/sample\n"
     ]
    }
   ],
   "source": [
    "best_model = models['words_context_syntactic_budi_20']\n",
    "raw_pred_best = best_model.predict([text_1, text_2, prev_1, prev_2, next_1, next_2, syntactic_1, syntactic_2, relation], verbose=1)\n",
    "pred_best_wo_sc = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred_best)\n",
    "pred_best_w_sc = get_anaphora_scores_by_antecedent(pairs.m1_id, pairs.m2_id, raw_pred_best, singletons)\n",
    "pred_chains_best_wo_sc = BestFirstClusterer().get_chains(pred_best_wo_sc, 0.2)\n",
    "pred_chains_best_w_sc = BestFirstClusterer().get_chains(pred_best_w_sc, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_chains(chains):\n",
    "    return [[(id, ' '.join(get_markable_text(id))) for id in chain] for chain in chains if len(chain) > 1]\n",
    "\n",
    "def save_chains(chains, file_path):\n",
    "    chains = convert_chains(chains)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(json.dumps(chains, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2252, 'deputi gubernur'),\n",
       "  (2255, 'hartadi a sarwono'),\n",
       "  (2258, 'ia'),\n",
       "  (2266, 'hartadi'),\n",
       "  (2270, 'hartadi'),\n",
       "  (2278, 'nya'),\n",
       "  (2286, 'hartadi'),\n",
       "  (2290, 'nya'),\n",
       "  (2303, 'ia')],\n",
       " [(2254, 'bi'), (2268, 'bi')],\n",
       " [(2316, 'ansari'), (2323, 'ansari')],\n",
       " [(2330, 'menteri keuangan sri mulyani'),\n",
       "  (2337, 'sri mulyani'),\n",
       "  (2367, 'mulyani'),\n",
       "  (2375, 'mulyani')],\n",
       " [(2393, 'direktur aali'), (2394, 'santosa'), (2399, 'nya')],\n",
       " [(2423, 'deputi senior'),\n",
       "  (2426, 'miranda s goeltom'),\n",
       "  (2436, 'miranda'),\n",
       "  (2450, 'miranda')],\n",
       " [(2469, 'deputi gubernur senior bi'),\n",
       "  (2470, 'miranda s goeltom'),\n",
       "  (2480, 'miranda'),\n",
       "  (2488, 'nya'),\n",
       "  (2489, 'itung-itung bi')],\n",
       " [(2510, 'bank mandiri'),\n",
       "  (2512, 'ti'),\n",
       "  (2517, 'nya'),\n",
       "  (2520, 'kami'),\n",
       "  (2521, 'nya'),\n",
       "  (2524, 'direktur teknologi dan operasional bank mandiri'),\n",
       "  (2525, 'sasmita'),\n",
       "  (2528, 'dia'),\n",
       "  (2530, 'bank mandiri'),\n",
       "  (2535, 'ia'),\n",
       "  (2543, 'kita'),\n",
       "  (2545, 'nya'),\n",
       "  (2546, 'bank mandiri'),\n",
       "  (2551, 'nya')],\n",
       " [(2565, 'menteri keuangan sri mulyani indrawati'),\n",
       "  (2592, 'nya'),\n",
       "  (2603, 'menko perekonomian boediono'),\n",
       "  (2620, 'nya'),\n",
       "  (2621, 'boediono'),\n",
       "  (2630, 'nya'),\n",
       "  (2640, 'nya')],\n",
       " [(2652, 'pefindo'),\n",
       "  (2668, 'analis pefindo ronald hertanto'),\n",
       "  (2669, 'nya'),\n",
       "  (2672, 'dia')],\n",
       " [(2677, 'trje'),\n",
       "  (2692, 'pt tri usaha bhakti'),\n",
       "  (2693, 'trje'),\n",
       "  (2697, 'trje')],\n",
       " [(2718, 'adb'), (2725, 'adb'), (2760, 'adb')],\n",
       " [(2734, 'rm dewo broto joko p'),\n",
       "  (2738, 'nya'),\n",
       "  (2744, 'nya'),\n",
       "  (2750, 'plta genyem'),\n",
       "  (2752, 'nya'),\n",
       "  (2759, 'nya'),\n",
       "  (2766, 'nya'),\n",
       "  (2767, 'dewo')],\n",
       " [(2774, 'pt nibung arthamulia'), (2789, 'pt nibung arthamulia')],\n",
       " [(2777, 'fitri barnas'),\n",
       "  (2778, 'nya'),\n",
       "  (2779, 'ketua bapepam - lk'),\n",
       "  (2786, 'ia')],\n",
       " [(2837, 'anwar'), (2869, 'nya'), (2870, 'dia'), (2881, 'nya'), (2882, 'ia')],\n",
       " [(2894, 'indonesia'), (2942, 'indonesia')],\n",
       " [(2902, 'fitch'), (2956, 'fitch')],\n",
       " [(1916, 'pt astra otoparts tbk'),\n",
       "  (1917, 'nya'),\n",
       "  (1918, 'pt exedy indonesia'),\n",
       "  (1931, 'pt exedy indonesia')],\n",
       " [(1933, 'sekretaris perusahaan astra otoparts'),\n",
       "  (1934, 'kartina rahayu'),\n",
       "  (1937, 'dia'),\n",
       "  (1940, 'dia'),\n",
       "  (1952, 'nya')],\n",
       " [(1953, 'menkeu sri mulyani indrawati'), (1964, 'dia')]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_chains(pred_chains_best_wo_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2254, 'bi'), (2268, 'bi')],\n",
       " [(2255, 'hartadi a sarwono'),\n",
       "  (2258, 'ia'),\n",
       "  (2266, 'hartadi'),\n",
       "  (2270, 'hartadi'),\n",
       "  (2278, 'nya'),\n",
       "  (2286, 'hartadi'),\n",
       "  (2290, 'nya'),\n",
       "  (2303, 'ia')],\n",
       " [(2316, 'ansari'), (2323, 'ansari')],\n",
       " [(2330, 'menteri keuangan sri mulyani'),\n",
       "  (2337, 'sri mulyani'),\n",
       "  (2367, 'mulyani'),\n",
       "  (2375, 'mulyani')],\n",
       " [(2393, 'direktur aali'), (2394, 'santosa'), (2399, 'nya')],\n",
       " [(2426, 'miranda s goeltom'), (2436, 'miranda'), (2450, 'miranda')],\n",
       " [(2469, 'deputi gubernur senior bi'),\n",
       "  (2470, 'miranda s goeltom'),\n",
       "  (2480, 'miranda'),\n",
       "  (2488, 'nya'),\n",
       "  (2489, 'itung-itung bi')],\n",
       " [(2510, 'bank mandiri'),\n",
       "  (2517, 'nya'),\n",
       "  (2521, 'nya'),\n",
       "  (2524, 'direktur teknologi dan operasional bank mandiri'),\n",
       "  (2528, 'dia'),\n",
       "  (2530, 'bank mandiri'),\n",
       "  (2535, 'ia'),\n",
       "  (2545, 'nya'),\n",
       "  (2546, 'bank mandiri'),\n",
       "  (2551, 'nya')],\n",
       " [(2565, 'menteri keuangan sri mulyani indrawati'),\n",
       "  (2592, 'nya'),\n",
       "  (2603, 'menko perekonomian boediono'),\n",
       "  (2620, 'nya'),\n",
       "  (2621, 'boediono'),\n",
       "  (2630, 'nya'),\n",
       "  (2640, 'nya')],\n",
       " [(2652, 'pefindo'),\n",
       "  (2668, 'analis pefindo ronald hertanto'),\n",
       "  (2669, 'nya'),\n",
       "  (2672, 'dia')],\n",
       " [(2692, 'pt tri usaha bhakti'), (2694, 'nya')],\n",
       " [(2718, 'adb'), (2725, 'adb'), (2760, 'adb')],\n",
       " [(2738, 'nya'),\n",
       "  (2744, 'nya'),\n",
       "  (2752, 'nya'),\n",
       "  (2759, 'nya'),\n",
       "  (2766, 'nya'),\n",
       "  (2767, 'dewo')],\n",
       " [(2777, 'fitri barnas'),\n",
       "  (2778, 'nya'),\n",
       "  (2779, 'ketua bapepam - lk'),\n",
       "  (2786, 'ia')],\n",
       " [(2837, 'anwar'), (2869, 'nya'), (2870, 'dia'), (2881, 'nya'), (2882, 'ia')],\n",
       " [(2894, 'indonesia'), (2942, 'indonesia')],\n",
       " [(2902, 'fitch'), (2956, 'fitch')],\n",
       " [(1933, 'sekretaris perusahaan astra otoparts'),\n",
       "  (1934, 'kartina rahayu'),\n",
       "  (1937, 'dia'),\n",
       "  (1940, 'dia'),\n",
       "  (1952, 'nya')],\n",
       " [(1953, 'menkeu sri mulyani indrawati'), (1964, 'dia')]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_chains(pred_chains_best_w_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2252, 'deputi gubernur'), (2253, 'bank indonesia')],\n",
       " [(2255, 'hartadi a sarwono'),\n",
       "  (2258, 'ia'),\n",
       "  (2266, 'hartadi'),\n",
       "  (2269, 'jakarta'),\n",
       "  (2270, 'hartadi'),\n",
       "  (2286, 'hartadi'),\n",
       "  (1927, 'kami'),\n",
       "  (1933, 'sekretaris perusahaan astra otoparts'),\n",
       "  (1934, 'kartina rahayu'),\n",
       "  (1937, 'dia'),\n",
       "  (1940, 'dia'),\n",
       "  (1946, 'nya'),\n",
       "  (1952, 'nya'),\n",
       "  (1953, 'menkeu sri mulyani indrawati'),\n",
       "  (1964, 'dia')],\n",
       " [(2303, 'ia'),\n",
       "  (2311,\n",
       "   'dirjend industri logam mesin tekstil departemen perindustrian ansari bukhari'),\n",
       "  (2316, 'ansari'),\n",
       "  (2323, 'ansari')],\n",
       " [(2330, 'menteri keuangan sri mulyani'),\n",
       "  (2337, 'sri mulyani'),\n",
       "  (2367, 'mulyani'),\n",
       "  (2383, 'nya')],\n",
       " [(2339, 'indonesia investor forum'), (2368, 'indonesia investor forum')],\n",
       " [(2393, 'direktur aali'),\n",
       "  (2394, 'santosa'),\n",
       "  (2399, 'nya'),\n",
       "  (2405, 'nya'),\n",
       "  (2423, 'deputi senior'),\n",
       "  (2424, 'bank indonesia'),\n",
       "  (2426, 'miranda s goeltom'),\n",
       "  (2436, 'miranda'),\n",
       "  (2450, 'miranda'),\n",
       "  (2460, 'kami'),\n",
       "  (2466, 'nya'),\n",
       "  (2469, 'deputi gubernur senior bi'),\n",
       "  (2470, 'miranda s goeltom'),\n",
       "  (2480, 'miranda')],\n",
       " [(2455, 'pertumbuhan ekonomi indonesia'),\n",
       "  (2471, 'pertumbuhan ekonomi indonesia'),\n",
       "  (2495, 'pertumbuhan ekonomi indonesia')],\n",
       " [(2510, 'bank mandiri'), (2530, 'bank mandiri'), (2546, 'bank mandiri')],\n",
       " [(2517, 'nya'),\n",
       "  (2524, 'direktur teknologi dan operasional bank mandiri'),\n",
       "  (2525, 'sasmita'),\n",
       "  (2528, 'dia'),\n",
       "  (2535, 'ia'),\n",
       "  (2543, 'kita'),\n",
       "  (2545, 'nya'),\n",
       "  (2565, 'menteri keuangan sri mulyani indrawati')],\n",
       " [(2592, 'nya'),\n",
       "  (2603, 'menko perekonomian boediono'),\n",
       "  (2620, 'nya'),\n",
       "  (2621, 'boediono'),\n",
       "  (2630, 'nya'),\n",
       "  (2640, 'nya'),\n",
       "  (2652, 'pefindo'),\n",
       "  (2655, 'trje'),\n",
       "  (2668, 'analis pefindo ronald hertanto'),\n",
       "  (2669, 'nya'),\n",
       "  (2672, 'dia'),\n",
       "  (2677, 'trje'),\n",
       "  (2693, 'trje'),\n",
       "  (2697, 'trje'),\n",
       "  (2702, 'nya')],\n",
       " [(2638, '<angka> dolar as'), (2642, '<angka> dolar as')],\n",
       " [(2690, 'jurong engineering limited of singapore'), (2691, 'jel')],\n",
       " [(2718, 'adb'),\n",
       "  (2725, 'adb'),\n",
       "  (2726, 'sendiri'),\n",
       "  (2727, 'nya'),\n",
       "  (2733, 'direktur pendanaan luar negeri multilateral bappenas'),\n",
       "  (2734, 'rm dewo broto joko p'),\n",
       "  (2735, 'nya'),\n",
       "  (2738, 'nya'),\n",
       "  (2744, 'nya'),\n",
       "  (2750, 'plta genyem'),\n",
       "  (2751, 'papua'),\n",
       "  (2752, 'nya'),\n",
       "  (2759, 'nya'),\n",
       "  (2760, 'adb'),\n",
       "  (2762, 'gorontalo'),\n",
       "  (2765, 'kita'),\n",
       "  (2766, 'nya'),\n",
       "  (2767, 'dewo'),\n",
       "  (2776, 'sekretaris perusahaan bakrie sumatera plantations tbk'),\n",
       "  (2777, 'fitri barnas'),\n",
       "  (2778, 'nya'),\n",
       "  (2786, 'ia')],\n",
       " [(2774, 'pt nibung arthamulia'), (2789, 'pt nibung arthamulia')],\n",
       " [(2791, 'pgas'), (2796, 'saham pgas'), (2797, 'nya')],\n",
       " [(2813, 'nya'),\n",
       "  (2815, 'dirjen bea dan cukai departemen keuangan anwar suprijad'),\n",
       "  (2834, 'anwar suprijad'),\n",
       "  (2837, 'anwar'),\n",
       "  (2847, 'nya'),\n",
       "  (2848, 'kita')],\n",
       " [(2857, 'dpr'),\n",
       "  (2866, 'dpr'),\n",
       "  (2869, 'nya'),\n",
       "  (2870, 'dia'),\n",
       "  (2881, 'nya'),\n",
       "  (2882, 'ia'),\n",
       "  (2925, 'nya')],\n",
       " [(2888, 'lembaga pemeringkat internasional fitch ratings'), (2902, 'fitch')],\n",
       " [(2920, 'ai ling ngiam'), (2950, 'nya')],\n",
       " [(1916, 'pt astra otoparts tbk'), (1930, 'pt astra otoparts')],\n",
       " [(1918, 'pt exedy indonesia'), (1931, 'pt exedy indonesia')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_chains(baseline_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2255, 'hartadi a sarwono'),\n",
       "  (2258, 'ia'),\n",
       "  (2266, 'hartadi'),\n",
       "  (2270, 'hartadi'),\n",
       "  (2286, 'hartadi'),\n",
       "  (2303, 'ia')],\n",
       " [(2311,\n",
       "   'dirjend industri logam mesin tekstil departemen perindustrian ansari bukhari'),\n",
       "  (2316, 'ansari'),\n",
       "  (2323, 'ansari')],\n",
       " [(2330, 'menteri keuangan sri mulyani'),\n",
       "  (2337, 'sri mulyani'),\n",
       "  (2367, 'mulyani'),\n",
       "  (2375, 'mulyani')],\n",
       " [(2333, 'pdb'), (2343, 'pdb'), (2347, 'pdb')],\n",
       " [(2393, 'direktur aali'), (2394, 'santosa'), (2399, 'nya')],\n",
       " [(2426, 'miranda s goeltom'),\n",
       "  (2436, 'miranda'),\n",
       "  (2450, 'miranda'),\n",
       "  (2464, 'nya'),\n",
       "  (2466, 'nya')],\n",
       " [(2469, 'deputi gubernur senior bi'),\n",
       "  (2470, 'miranda s goeltom'),\n",
       "  (2480, 'miranda'),\n",
       "  (2488, 'nya')],\n",
       " [(2510, 'bank mandiri'),\n",
       "  (2517, 'nya'),\n",
       "  (2520, 'kami'),\n",
       "  (2530, 'bank mandiri'),\n",
       "  (2546, 'bank mandiri'),\n",
       "  (2554, 'nya')],\n",
       " [(2524, 'direktur teknologi dan operasional bank mandiri'),\n",
       "  (2525, 'sasmita'),\n",
       "  (2528, 'dia'),\n",
       "  (2535, 'ia'),\n",
       "  (2545, 'nya')],\n",
       " [(2565, 'menteri keuangan sri mulyani indrawati'),\n",
       "  (2592, 'nya'),\n",
       "  (2640, 'nya')],\n",
       " [(2603, 'menko perekonomian boediono'),\n",
       "  (2620, 'nya'),\n",
       "  (2621, 'boediono'),\n",
       "  (2630, 'nya')],\n",
       " [(2668, 'analis pefindo ronald hertanto'), (2669, 'nya'), (2672, 'dia')],\n",
       " [(2677, 'trje'), (2693, 'trje'), (2697, 'trje')],\n",
       " [(2691, 'jel'), (2703, 'jel')],\n",
       " [(2718, 'adb'), (2725, 'adb'), (2760, 'adb')],\n",
       " [(2733, 'direktur pendanaan luar negeri multilateral bappenas'),\n",
       "  (2734, 'rm dewo broto joko p'),\n",
       "  (2735, 'nya'),\n",
       "  (2738, 'nya'),\n",
       "  (2744, 'nya'),\n",
       "  (2752, 'nya'),\n",
       "  (2767, 'dewo')],\n",
       " [(2774, 'pt nibung arthamulia'), (2789, 'pt nibung arthamulia')],\n",
       " [(2776, 'sekretaris perusahaan bakrie sumatera plantations tbk'),\n",
       "  (2777, 'fitri barnas'),\n",
       "  (2778, 'nya'),\n",
       "  (2786, 'ia')],\n",
       " [(2815, 'dirjen bea dan cukai departemen keuangan anwar suprijad'),\n",
       "  (2834, 'anwar suprijad'),\n",
       "  (2837, 'anwar'),\n",
       "  (2869, 'nya'),\n",
       "  (2870, 'dia'),\n",
       "  (2881, 'nya'),\n",
       "  (2882, 'ia')],\n",
       " [(2857, 'dpr'), (2866, 'dpr')],\n",
       " [(2888, 'lembaga pemeringkat internasional fitch ratings'),\n",
       "  (2902, 'fitch'),\n",
       "  (2956, 'fitch')],\n",
       " [(2920, 'ai ling ngiam'),\n",
       "  (2925, 'nya'),\n",
       "  (2950, 'nya'),\n",
       "  (2951, 'nya'),\n",
       "  (2976, 'nya')],\n",
       " [(2942, 'indonesia'), (2943, 'nya')],\n",
       " [(1916, 'pt astra otoparts tbk'),\n",
       "  (1917, 'nya'),\n",
       "  (1927, 'kami'),\n",
       "  (1930, 'pt astra otoparts')],\n",
       " [(1918, 'pt exedy indonesia'),\n",
       "  (1925, 'exedy corporation'),\n",
       "  (1931, 'pt exedy indonesia'),\n",
       "  (1932, 'exedy corporation')],\n",
       " [(1933, 'sekretaris perusahaan astra otoparts'),\n",
       "  (1934, 'kartina rahayu'),\n",
       "  (1937, 'dia'),\n",
       "  (1940, 'dia'),\n",
       "  (1952, 'nya')],\n",
       " [(1953, 'menkeu sri mulyani indrawati'), (1964, 'dia')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_chains(label_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_chains(pred_chains_best_w_sc, 'result/with_singleton_classifier.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_chains(pred_chains_best_wo_sc, 'result/without_singleton_classifier.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
