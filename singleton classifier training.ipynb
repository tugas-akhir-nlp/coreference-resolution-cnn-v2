{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.singleton_classifier import SingletonClassifierModelBuilder\n",
    "from functools import reduce\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>num_words</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 2]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[6, 7, 8, 9, 10, 2, 11, 10, 12, 13]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[6, 7, 8]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[9, 10, 2, 11, 10, 12, 13, 14, 15, 16]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[2, 11, 10, 12, 13, 14, 15, 16, 17, 18]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 2, 11]</td>\n",
       "      <td>[13, 14, 15, 16, 17, 18, 4, 5, 19, 20]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       text  is_pronoun                     entity_type  is_proper_name  \\\n",
       "0   1        [1]           0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]               0   \n",
       "1   2     [4, 5]           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]               0   \n",
       "2   3  [6, 7, 8]           0  [0, 0, 0, 1, 0, 0, 1, 0, 0, 0]               1   \n",
       "3   4       [10]           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]               0   \n",
       "4   5   [10, 12]           0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]               0   \n",
       "\n",
       "   is_first_person  num_words                    previous_words  \\\n",
       "0                0          1                                []   \n",
       "1                0          2                         [1, 2, 3]   \n",
       "2                0          3                   [1, 2, 3, 4, 5]   \n",
       "3                0          1       [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "4                0          2  [3, 4, 5, 6, 7, 8, 9, 10, 2, 11]   \n",
       "\n",
       "                                next_words is_singleton  \n",
       "0          [2, 3, 4, 5, 6, 7, 8, 9, 10, 2]   [0.0, 1.0]  \n",
       "1      [6, 7, 8, 9, 10, 2, 11, 10, 12, 13]   [0.0, 1.0]  \n",
       "2   [9, 10, 2, 11, 10, 12, 13, 14, 15, 16]   [1.0, 0.0]  \n",
       "3  [2, 11, 10, 12, 13, 14, 15, 16, 17, 18]   [0.0, 1.0]  \n",
       "4   [13, 14, 15, 16, 17, 18, 4, 5, 19, 20]   [0.0, 1.0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_markable_dataframe(\"data/training/markables.csv\", word_vector, idx_by_word)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person', 'num_words']]\n",
    "\n",
    "data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "label = np.vstack(data.is_singleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model = words_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 4s 707us/step - loss: 0.3135 - acc: 0.8440\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 2s 418us/step - loss: 0.2049 - acc: 0.8971\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 2s 444us/step - loss: 0.1746 - acc: 0.9161\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 2s 435us/step - loss: 0.1620 - acc: 0.9279\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 2s 430us/step - loss: 0.1421 - acc: 0.9364\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 2s 443us/step - loss: 0.1346 - acc: 0.9364\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 2s 456us/step - loss: 0.1197 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 2s 460us/step - loss: 0.1149 - acc: 0.9384\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 2s 433us/step - loss: 0.1125 - acc: 0.9402\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 2s 447us/step - loss: 0.1074 - acc: 0.9416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3be42240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_model.fit([data_text], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_model.save('models/singleton_classifiers/words.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model = context_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 7s 1ms/step - loss: 0.4773 - acc: 0.8239\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 5s 915us/step - loss: 0.4091 - acc: 0.8400\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 4s 840us/step - loss: 0.3512 - acc: 0.8466\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 4s 792us/step - loss: 0.3016 - acc: 0.8674\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 4s 778us/step - loss: 0.2544 - acc: 0.8857\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 4s 776us/step - loss: 0.2226 - acc: 0.9066\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 4s 827us/step - loss: 0.1793 - acc: 0.9199\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 4s 819us/step - loss: 0.1689 - acc: 0.9326\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 4s 882us/step - loss: 0.1294 - acc: 0.9473\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 4s 890us/step - loss: 0.1080 - acc: 0.9563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a40188160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model.fit([data_previous_words, data_next_words], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_model.save('models/singleton_classifiers/context.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=True,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_model = syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 2s 316us/step - loss: 0.3927 - acc: 0.8388\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 0s 97us/step - loss: 0.2861 - acc: 0.8388\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 0s 99us/step - loss: 0.2647 - acc: 0.8402\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 0s 97us/step - loss: 0.2599 - acc: 0.8557\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 0s 98us/step - loss: 0.2556 - acc: 0.8543\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 0s 98us/step - loss: 0.2538 - acc: 0.8579\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 0s 98us/step - loss: 0.2503 - acc: 0.8613\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 0s 98us/step - loss: 0.2542 - acc: 0.8569\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 0s 98us/step - loss: 0.2495 - acc: 0.8661\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 1s 117us/step - loss: 0.2468 - acc: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ea31898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_model.fit([data_syntactic], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syntactic_model.save('models/singleton_classifiers/syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_model = words_context_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 8s 2ms/step - loss: 0.3226 - acc: 0.8543\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1832 - acc: 0.9179\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1446 - acc: 0.9388\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1312 - acc: 0.9459\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0944 - acc: 0.9634\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0738 - acc: 0.9712\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0576 - acc: 0.9762\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0540 - acc: 0.9807\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0404 - acc: 0.9877\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0445 - acc: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a41d4b9b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_context_model.fit([data_text, data_previous_words, data_next_words], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_context_model.save('models/singleton_classifiers/words_context.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model = words_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 4s 874us/step - loss: 0.3004 - acc: 0.8531\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 3s 511us/step - loss: 0.2120 - acc: 0.8923\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 3s 542us/step - loss: 0.1677 - acc: 0.9179\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 3s 507us/step - loss: 0.1510 - acc: 0.9289\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 3s 502us/step - loss: 0.1334 - acc: 0.9382\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 3s 500us/step - loss: 0.1312 - acc: 0.9372\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 2s 497us/step - loss: 0.1195 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 3s 515us/step - loss: 0.1291 - acc: 0.9416\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 3s 607us/step - loss: 0.1171 - acc: 0.9438\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 3s 532us/step - loss: 0.1129 - acc: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4c952978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_syntactic_model.fit([data_text, data_syntactic], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_syntactic_model.save('models/singleton_classifiers/words_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_model = context_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 8s 2ms/step - loss: 0.4713 - acc: 0.8309\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.3091 - acc: 0.8555\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 4s 871us/step - loss: 0.2186 - acc: 0.8965\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 5s 1ms/step - loss: 0.1714 - acc: 0.9261\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 5s 936us/step - loss: 0.1548 - acc: 0.9352\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 5s 935us/step - loss: 0.1167 - acc: 0.9533\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 5s 1ms/step - loss: 0.1010 - acc: 0.9622\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 5s 948us/step - loss: 0.0735 - acc: 0.9736\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 5s 932us/step - loss: 0.0665 - acc: 0.9771\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0577 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4ef4aa20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_syntactic_model.fit([data_previous_words, data_next_words, data_syntactic], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context_syntactic_model.save('models/singleton_classifiers/context_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_model = words_context_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5032/5032 [==============================] - 10s 2ms/step - loss: 0.4057 - acc: 0.8146\n",
      "Epoch 2/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.2110 - acc: 0.9014\n",
      "Epoch 3/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1511 - acc: 0.9384\n",
      "Epoch 4/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1274 - acc: 0.9499\n",
      "Epoch 5/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.1006 - acc: 0.9585\n",
      "Epoch 6/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0842 - acc: 0.9714\n",
      "Epoch 7/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0789 - acc: 0.9738\n",
      "Epoch 8/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0575 - acc: 0.9807\n",
      "Epoch 9/10\n",
      "5032/5032 [==============================] - 6s 1ms/step - loss: 0.0538 - acc: 0.9827\n",
      "Epoch 10/10\n",
      "5032/5032 [==============================] - 7s 1ms/step - loss: 0.0582 - acc: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5018f2e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_context_syntactic_model.fit([data_text, data_previous_words, data_next_words, data_syntactic], label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_context_syntactic_model.save('models/singleton_classifiers/words_context_syntactic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python TA",
   "language": "python",
   "name": "ta-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
