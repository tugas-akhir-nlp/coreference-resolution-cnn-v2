{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_helper import get_markable_dataframe, get_embedding_variables\n",
    "from model_builders.singleton_classifier import SingletonClassifierModelBuilder\n",
    "from functools import reduce\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'\n",
    "indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'\n",
    "\n",
    "word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_pronoun</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>is_proper_name</th>\n",
       "      <th>is_first_person</th>\n",
       "      <th>previous_words</th>\n",
       "      <th>next_words</th>\n",
       "      <th>is_singleton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 2]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[6, 7, 8, 9, 10, 2, 11, 12, 13, 14]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[6, 7, 8]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[9, 10, 2, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[2, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[12, 13]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 2, 11]</td>\n",
       "      <td>[14, 15, 16, 17, 18, 19, 4, 5, 20, 21]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       text  is_pronoun                     entity_type  is_proper_name  \\\n",
       "0   1        [1]           0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]               0   \n",
       "1   2     [4, 5]           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]               0   \n",
       "2   3  [6, 7, 8]           0  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0]               1   \n",
       "3   4       [10]           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]               0   \n",
       "4   5   [12, 13]           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]               0   \n",
       "\n",
       "   is_first_person                    previous_words  \\\n",
       "0                0                                []   \n",
       "1                0                         [1, 2, 3]   \n",
       "2                0                   [1, 2, 3, 4, 5]   \n",
       "3                0       [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "4                0  [3, 4, 5, 6, 7, 8, 9, 10, 2, 11]   \n",
       "\n",
       "                                next_words is_singleton  \n",
       "0          [2, 3, 4, 5, 6, 7, 8, 9, 10, 2]   [0.0, 1.0]  \n",
       "1      [6, 7, 8, 9, 10, 2, 11, 12, 13, 14]   [0.0, 1.0]  \n",
       "2   [9, 10, 2, 11, 12, 13, 14, 15, 16, 17]   [1.0, 0.0]  \n",
       "3  [2, 11, 12, 13, 14, 15, 16, 17, 18, 19]   [0.0, 1.0]  \n",
       "4   [14, 15, 16, 17, 18, 19, 4, 5, 20, 21]   [0.0, 1.0]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_markable_dataframe(\"data/training/markables.csv\", word_vector, idx_by_word)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 10\n",
    "max_prev_words_length = 10\n",
    "max_next_words_length = 10\n",
    "\n",
    "data_text = pad_sequences(data.text, maxlen=max_text_length, padding='post')\n",
    "data_previous_words = pad_sequences(data.previous_words.map(lambda seq: seq[(-1*max_prev_words_length):]), maxlen=max_prev_words_length, padding='pre')\n",
    "data_next_words = pad_sequences(data.next_words.map(lambda seq: seq[:max_next_words_length]), maxlen=max_next_words_length, padding='post')\n",
    "data_syntactic = data[['is_pronoun', 'entity_type', 'is_proper_name', 'is_first_person']]\n",
    "\n",
    "data_syntactic = np.array(list(map(lambda p: reduce(lambda x,y: x + y, [i if type(i) is list else [i] for i in p]), data_syntactic.values)))\n",
    "label = np.vstack(data.is_singleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0314 11:20:07.272945 139668807812928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:20:08.513025 139668807812928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:135: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:20:08.570456 139668807812928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0314 11:20:08.648583 139668807812928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:123: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "words_model = words_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 2s 411us/sample - loss: 0.3195 - acc: 0.8555\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 1s 211us/sample - loss: 0.2180 - acc: 0.9026\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.1724 - acc: 0.9175\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.1424 - acc: 0.9332\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 1s 216us/sample - loss: 0.1246 - acc: 0.9396\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 1s 211us/sample - loss: 0.1226 - acc: 0.9438\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 1s 211us/sample - loss: 0.1120 - acc: 0.9448\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.1048 - acc: 0.9461\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 1s 209us/sample - loss: 0.1052 - acc: 0.9477\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 1s 212us/sample - loss: 0.0963 - acc: 0.9483\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.0991 - acc: 0.9481\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.0977 - acc: 0.9479\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 1s 214us/sample - loss: 0.0955 - acc: 0.9473\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 1s 214us/sample - loss: 0.1031 - acc: 0.9479\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 1s 209us/sample - loss: 0.1054 - acc: 0.9432\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 1s 214us/sample - loss: 0.1001 - acc: 0.9444\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.1024 - acc: 0.9457\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.0969 - acc: 0.9442\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 1s 213us/sample - loss: 0.0963 - acc: 0.9465\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 1s 212us/sample - loss: 0.0889 - acc: 0.9493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0678632a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_model.fit([data_text], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_model.save('models/singleton_classifiers/words.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model = context_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 2s 336us/sample - loss: 0.5226 - acc: 0.8086\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 1s 292us/sample - loss: 0.4339 - acc: 0.8382\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 1s 293us/sample - loss: 0.3717 - acc: 0.8480\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 1s 291us/sample - loss: 0.3226 - acc: 0.8611\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 1s 293us/sample - loss: 0.2828 - acc: 0.8702\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 1s 290us/sample - loss: 0.2275 - acc: 0.8899\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 1s 292us/sample - loss: 0.2041 - acc: 0.9060\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 1s 288us/sample - loss: 0.1875 - acc: 0.9112\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 1s 292us/sample - loss: 0.1391 - acc: 0.9400\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 1s 294us/sample - loss: 0.1354 - acc: 0.9469\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 1s 290us/sample - loss: 0.1404 - acc: 0.9471\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 1s 289us/sample - loss: 0.1194 - acc: 0.9571\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 1s 289us/sample - loss: 0.1109 - acc: 0.9557\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 1s 291us/sample - loss: 0.0950 - acc: 0.9624\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 1s 294us/sample - loss: 0.0940 - acc: 0.9698\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 1s 289us/sample - loss: 0.0772 - acc: 0.9744\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 1s 287us/sample - loss: 0.0649 - acc: 0.9785\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 1s 289us/sample - loss: 0.0776 - acc: 0.9750\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 1s 288us/sample - loss: 0.0617 - acc: 0.9773\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 1s 293us/sample - loss: 0.0540 - acc: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f06641845f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model.fit([data_previous_words, data_next_words], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model.save('models/singleton_classifiers/context.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=True,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_model = syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 1s 182us/sample - loss: 0.4004 - acc: 0.8349\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 1s 153us/sample - loss: 0.2681 - acc: 0.8454\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 1s 153us/sample - loss: 0.2550 - acc: 0.8569\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 1s 150us/sample - loss: 0.2497 - acc: 0.8529\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 1s 156us/sample - loss: 0.2519 - acc: 0.8527\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 1s 157us/sample - loss: 0.2493 - acc: 0.8569\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 1s 152us/sample - loss: 0.2505 - acc: 0.8575\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 1s 154us/sample - loss: 0.2478 - acc: 0.8623\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 1s 155us/sample - loss: 0.2479 - acc: 0.8619\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 1s 153us/sample - loss: 0.2470 - acc: 0.8625\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 1s 152us/sample - loss: 0.2486 - acc: 0.8615\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 1s 157us/sample - loss: 0.2475 - acc: 0.8637\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 1s 153us/sample - loss: 0.2466 - acc: 0.8579\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 1s 154us/sample - loss: 0.2456 - acc: 0.8605\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 1s 155us/sample - loss: 0.2466 - acc: 0.8607\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 1s 155us/sample - loss: 0.2472 - acc: 0.8599\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 1s 156us/sample - loss: 0.2457 - acc: 0.8627\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 1s 155us/sample - loss: 0.2469 - acc: 0.8609\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 1s 154us/sample - loss: 0.2444 - acc: 0.8625\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 1s 156us/sample - loss: 0.2460 - acc: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0610415860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_model.fit([data_syntactic], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_model.save('models/singleton_classifiers/syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=False,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_model = words_context_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 2s 430us/sample - loss: 0.3177 - acc: 0.8547\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 2s 359us/sample - loss: 0.1896 - acc: 0.9141\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 2s 363us/sample - loss: 0.1257 - acc: 0.9473\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 2s 364us/sample - loss: 0.0957 - acc: 0.9620\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 2s 357us/sample - loss: 0.0736 - acc: 0.9728\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 2s 357us/sample - loss: 0.0710 - acc: 0.9734\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 2s 359us/sample - loss: 0.0604 - acc: 0.9767\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 2s 358us/sample - loss: 0.0578 - acc: 0.9781\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 2s 359us/sample - loss: 0.0463 - acc: 0.9821\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 2s 357us/sample - loss: 0.0359 - acc: 0.9841\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 2s 356us/sample - loss: 0.0292 - acc: 0.9883\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 2s 356us/sample - loss: 0.0271 - acc: 0.9879\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 2s 358us/sample - loss: 0.0347 - acc: 0.9869\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 2s 359us/sample - loss: 0.0507 - acc: 0.9837\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 2s 360us/sample - loss: 0.0347 - acc: 0.9891\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 2s 357us/sample - loss: 0.0294 - acc: 0.9887\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 2s 359us/sample - loss: 0.0259 - acc: 0.9897\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 2s 357us/sample - loss: 0.0371 - acc: 0.9891\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 2s 352us/sample - loss: 0.0435 - acc: 0.9901\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 2s 353us/sample - loss: 0.0190 - acc: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05ec263160>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_context_model.fit([data_text, data_previous_words, data_next_words], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_model.save('models/singleton_classifiers/words_context.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=False, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model = words_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 1s 292us/sample - loss: 0.3861 - acc: 0.8031\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 1s 242us/sample - loss: 0.1883 - acc: 0.9042\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 1s 245us/sample - loss: 0.1517 - acc: 0.9217\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 1s 249us/sample - loss: 0.1266 - acc: 0.9338\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 1s 247us/sample - loss: 0.1182 - acc: 0.9404\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 1s 246us/sample - loss: 0.1159 - acc: 0.9366\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 1s 247us/sample - loss: 0.1079 - acc: 0.9422\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 1s 246us/sample - loss: 0.1075 - acc: 0.9374\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 1s 248us/sample - loss: 0.0994 - acc: 0.9485\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 1s 247us/sample - loss: 0.0989 - acc: 0.9446\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 1s 246us/sample - loss: 0.0974 - acc: 0.9475\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 1s 243us/sample - loss: 0.0943 - acc: 0.9479\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 1s 244us/sample - loss: 0.0982 - acc: 0.9471\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 1s 248us/sample - loss: 0.0910 - acc: 0.9453\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 1s 248us/sample - loss: 0.0924 - acc: 0.9471\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 1s 244us/sample - loss: 0.0907 - acc: 0.9487\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 1s 243us/sample - loss: 0.0928 - acc: 0.9505\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 1s 244us/sample - loss: 0.0881 - acc: 0.9507\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 1s 243us/sample - loss: 0.0888 - acc: 0.9483\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 1s 249us/sample - loss: 0.0867 - acc: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f059c784438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_syntactic_model.fit([data_text, data_syntactic], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_syntactic_model.save('models/singleton_classifiers/words_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=False, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_model = context_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 2s 382us/sample - loss: 0.4486 - acc: 0.8106\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 2s 312us/sample - loss: 0.2524 - acc: 0.8786\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 2s 318us/sample - loss: 0.1965 - acc: 0.9141\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 2s 320us/sample - loss: 0.1541 - acc: 0.9324\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 2s 321us/sample - loss: 0.1213 - acc: 0.9473\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 2s 316us/sample - loss: 0.1094 - acc: 0.9549\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 2s 313us/sample - loss: 0.0883 - acc: 0.9634\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 2s 318us/sample - loss: 0.0815 - acc: 0.9654\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 2s 320us/sample - loss: 0.0687 - acc: 0.9688\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 2s 318us/sample - loss: 0.0593 - acc: 0.9767\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 2s 319us/sample - loss: 0.0511 - acc: 0.9791\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 2s 321us/sample - loss: 0.0650 - acc: 0.9720\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 2s 318us/sample - loss: 0.0626 - acc: 0.9813\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 2s 319us/sample - loss: 0.0574 - acc: 0.9805\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 2s 317us/sample - loss: 0.0406 - acc: 0.9833\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 2s 314us/sample - loss: 0.0363 - acc: 0.9853\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 2s 322us/sample - loss: 0.0344 - acc: 0.9869\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 2s 322us/sample - loss: 0.0383 - acc: 0.9845\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 2s 320us/sample - loss: 0.0334 - acc: 0.9887\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 2s 319us/sample - loss: 0.0256 - acc: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f058419bbe0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_syntactic_model.fit([data_previous_words, data_next_words, data_syntactic], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_syntactic_model.save('models/singleton_classifiers/context_syntactic.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words + Context + Syntactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_model_builder = SingletonClassifierModelBuilder(\n",
    "    use_words_feature=True, \n",
    "    use_context_feature=True, \n",
    "    use_syntactic_feature=True,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    syntactic_features_num=data_syntactic.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_model = words_context_syntactic_model_builder.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5032/5032==============================] - 2s 467us/sample - loss: 0.3937 - acc: 0.8269\n",
      "Epoch 2/20\n",
      "5032/5032==============================] - 2s 387us/sample - loss: 0.1950 - acc: 0.9070\n",
      "Epoch 3/20\n",
      "5032/5032==============================] - 2s 392us/sample - loss: 0.1435 - acc: 0.9360\n",
      "Epoch 4/20\n",
      "5032/5032==============================] - 2s 385us/sample - loss: 0.0998 - acc: 0.9591\n",
      "Epoch 5/20\n",
      "5032/5032==============================] - 2s 386us/sample - loss: 0.0939 - acc: 0.9658\n",
      "Epoch 6/20\n",
      "5032/5032==============================] - 2s 389us/sample - loss: 0.0746 - acc: 0.9690\n",
      "Epoch 7/20\n",
      "5032/5032==============================] - 2s 390us/sample - loss: 0.0612 - acc: 0.9758\n",
      "Epoch 8/20\n",
      "5032/5032==============================] - 2s 388us/sample - loss: 0.0655 - acc: 0.9748\n",
      "Epoch 9/20\n",
      "5032/5032==============================] - 2s 386us/sample - loss: 0.0577 - acc: 0.9766\n",
      "Epoch 10/20\n",
      "5032/5032==============================] - 2s 386us/sample - loss: 0.0573 - acc: 0.9785\n",
      "Epoch 11/20\n",
      "5032/5032==============================] - 2s 392us/sample - loss: 0.0494 - acc: 0.9811\n",
      "Epoch 12/20\n",
      "5032/5032==============================] - 2s 395us/sample - loss: 0.0431 - acc: 0.9857\n",
      "Epoch 13/20\n",
      "5032/5032==============================] - 2s 393us/sample - loss: 0.0319 - acc: 0.9863\n",
      "Epoch 14/20\n",
      "5032/5032==============================] - 2s 393us/sample - loss: 0.0229 - acc: 0.9921\n",
      "Epoch 15/20\n",
      "5032/5032==============================] - 2s 388us/sample - loss: 0.0249 - acc: 0.9897\n",
      "Epoch 16/20\n",
      "5032/5032==============================] - 2s 392us/sample - loss: 0.0190 - acc: 0.9907\n",
      "Epoch 17/20\n",
      "5032/5032==============================] - 2s 388us/sample - loss: 0.0343 - acc: 0.9889\n",
      "Epoch 18/20\n",
      "5032/5032==============================] - 2s 389us/sample - loss: 0.0287 - acc: 0.9909\n",
      "Epoch 19/20\n",
      "5032/5032==============================] - 2s 389us/sample - loss: 0.0249 - acc: 0.9897\n",
      "Epoch 20/20\n",
      "5032/5032==============================] - 2s 390us/sample - loss: 0.0204 - acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f02544b7978>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_context_syntactic_model.fit([data_text, data_previous_words, data_next_words, data_syntactic], label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_context_syntactic_model.save('models/singleton_classifiers/words_context_syntactic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
